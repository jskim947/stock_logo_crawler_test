"""
ë¡œê³  ê´€ë¦¬ ì‹œìŠ¤í…œ í”„ë¡œí† íƒ€ì… - FastAPI ì„œë²„
ê¸°ì¡´ FastAPI ì„œë²„ë¥¼ í™œìš©í•˜ì—¬ ë¡œê³  ì¡°íšŒ/ê´€ë¦¬ ê¸°ëŠ¥ ì œê³µ
"""

from fastapi import FastAPI, HTTPException, Query, Depends, File, UploadFile, Form, Request
from fastapi.responses import FileResponse, JSONResponse, Response
from fastapi.middleware.cors import CORSMiddleware
from minio import Minio
import os
import asyncio
from typing import List, Dict, Optional
from pathlib import Path
import json
from datetime import datetime, date
import hashlib
import requests
# import aiohttp  # requestsë¡œ ëŒ€ì²´
from pydantic import BaseModel
# í¬ë¡¤ëŸ¬ëŠ” ì„ íƒì ìœ¼ë¡œ ì‚¬ìš© (playwright ë¯¸ì„¤ì¹˜ í™˜ê²½ ê°€ë“œ)
try:
    from crawler import LogoCrawler
except Exception as _crawler_import_error:
    LogoCrawler = None  # í¬ë¡¤ë§ ì—”ë“œí¬ì¸íŠ¸ì—ì„œ í•„ìš” ì‹œ ëŸ°íƒ€ì„ ì²´í¬
    print(f"âš ï¸  crawler ì„í¬íŠ¸ ì‹¤íŒ¨: {_crawler_import_error}")
from PIL import Image, ImageDraw, ImageFont
import io
# from loguru import logger  # ì„ì‹œë¡œ ë¹„í™œì„±í™”
import logging
logger = logging.getLogger(__name__)
# from slowapi import Limiter, _rate_limit_exceeded_handler
# from slowapi.util import get_remote_address
# from slowapi.errors import RateLimitExceeded

# ê¸°ì¡´ API í´ë¼ì´ì–¸íŠ¸
class ExistingAPIClient:
    def __init__(self, base_url: str):
        self.base_url = base_url.rstrip('/')
    
    async def query_table_async(self, schema: str, table: str, params: dict = None):
        """í…Œì´ë¸” ì¿¼ë¦¬ ì‹¤í–‰ (ë™ê¸° ë°©ì‹ìœ¼ë¡œ ëŒ€ì²´)"""
        try:
            # aiohttp ëŒ€ì‹  requests ì‚¬ìš©
            url = f"{self.base_url}/api/schemas/{schema}/tables/{table}/query"
            response = requests.get(url, params=params or {}, timeout=10)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            print(f"âŒ ê¸°ì¡´ API ì¿¼ë¦¬ ì˜¤ë¥˜: {e}")
            return None
    
    async def upsert_data_async(self, schema: str, table: str, data: dict):
        """ë°ì´í„° ì‚½ì…/ì—…ë°ì´íŠ¸ (ë™ê¸° ë°©ì‹ìœ¼ë¡œ ëŒ€ì²´)"""
        try:
            url = f"{self.base_url}/api/schemas/{schema}/tables/{table}/upsert"
            response = requests.post(url, json=data, timeout=10)
            print(f"ğŸ“¥ ì‘ë‹µ ìƒíƒœ: {response.status_code}")
            print(f"ğŸ“¥ ì‘ë‹µ ë‚´ìš©: {response.text}")
            response.raise_for_status()
            try:
                return response.json()
            except Exception:
                return {"text": response.text}
        except Exception as e:
            print(f"âŒ ê¸°ì¡´ API ë°ì´í„° ì…ë ¥ ì˜¤ë¥˜: {e}")
            return None

    # ì„ì‹œ í˜¸í™˜ìš© ë™ê¸° ë©”ì„œë“œ ìœ ì§€ (ì ì§„ ì „í™˜)
    def query_table(self, schema: str, table: str, params: dict = None):
        try:
            url = f"{self.base_url}/api/schemas/{schema}/tables/{table}/query"
            response = requests.get(url, params=params or {}, timeout=10)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            print(f"âŒ ê¸°ì¡´ API ì¿¼ë¦¬ ì˜¤ë¥˜: {e}")
            return None

    def upsert_data(self, schema: str, table: str, data: dict):
        try:
            url = f"{self.base_url}/api/schemas/{schema}/tables/{table}/upsert"
            response = requests.post(url, json=data, timeout=10)
            print(f"ğŸ“¥ ì—…ì„œíŠ¸ ìš”ì²­: {url}")
            print(f"ğŸ“¥ ì—…ì„œíŠ¸ í˜ì´ë¡œë“œ: {data}")
            print(f"ğŸ“¥ ì—…ì„œíŠ¸ ì‘ë‹µì½”ë“œ: {response.status_code}")
            print(f"ğŸ“¥ ì—…ì„œíŠ¸ ì‘ë‹µë³¸ë¬¸: {response.text}")
            response.raise_for_status()
            try:
                return response.json()
            except Exception:
                return {"text": response.text}
        except Exception as e:
            print(f"âŒ ê¸°ì¡´ API ë°ì´í„° ì…ë ¥ ì˜¤ë¥˜: {e}")
            return None

# ë ˆì´íŠ¸ë¦¬ë°‹ ì„¤ì • (ì„ì‹œ ë¹„í™œì„±í™”)
# limiter = Limiter(key_func=get_remote_address)

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="Logo Management System - Prototype",
    description="ì£¼ì‹ ë¡œê³  ìˆ˜ì§‘ ë° ê´€ë¦¬ ì‹œìŠ¤í…œ í”„ë¡œí† íƒ€ì…",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# ë ˆì´íŠ¸ë¦¬ë°‹ ë¯¸ë“¤ì›¨ì–´ ì¶”ê°€ (ì„ì‹œ ë¹„í™œì„±í™”)
# app.state.limiter = limiter
# app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì´ë¯¸ì§€ ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
def process_uploaded_image(image_data: bytes, target_size: int = 256, target_format: str = "PNG") -> bytes:
    """ì—…ë¡œë“œëœ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ì—¬ ì§€ì •ëœ í¬ê¸°ì™€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    try:
        print(f"ğŸ” ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘: {len(image_data)} bytes")
        
        # ì´ë¯¸ì§€ ì—´ê¸°
        image = Image.open(io.BytesIO(image_data))
        print(f"ğŸ“ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°: {image.size}, ëª¨ë“œ: {image.mode}")
        
        # RGBë¡œ ë³€í™˜ (íˆ¬ëª…ë„ ì œê±°)
        if image.mode in ('RGBA', 'LA', 'P'):
            # íˆ¬ëª…ë„ê°€ ìˆëŠ” ê²½ìš° í°ìƒ‰ ë°°ê²½ ì¶”ê°€
            background = Image.new('RGB', image.size, (255, 255, 255))
            if image.mode == 'P':
                image = image.convert('RGBA')
            background.paste(image, mask=image.split()[-1] if image.mode == 'RGBA' else None)
            image = background
        elif image.mode != 'RGB':
            image = image.convert('RGB')
        
        print(f"ğŸ”„ ë³€í™˜ í›„ ì´ë¯¸ì§€ ëª¨ë“œ: {image.mode}")
        
        # ì •ì‚¬ê°í˜•ìœ¼ë¡œ í¬ë¡­ (ì¤‘ì•™ ê¸°ì¤€)
        width, height = image.size
        if width != height:
            size = min(width, height)
            left = (width - size) // 2
            top = (height - size) // 2
            right = left + size
            bottom = top + size
            image = image.crop((left, top, right, bottom))
            print(f"âœ‚ï¸ í¬ë¡­ í›„ í¬ê¸°: {image.size}")
        
        # í¬ê¸° ì¡°ì •
        if image.size[0] != target_size:
            image = image.resize((target_size, target_size), Image.Resampling.LANCZOS)
            print(f"ğŸ“ ë¦¬ì‚¬ì´ì¦ˆ í›„ í¬ê¸°: {image.size}")
        
        # í˜•ì‹ì— ë”°ë¼ ë³€í™˜
        output = io.BytesIO()
        if target_format.upper() == "PNG":
            image.save(output, format="PNG", optimize=True)
        elif target_format.upper() == "WEBP":
            image.save(output, format="WEBP", quality=90, optimize=True)
        elif target_format.upper() == "JPEG":
            image.save(output, format="JPEG", quality=90, optimize=True)
        else:
            # ê¸°ë³¸ê°’ì€ PNG
            image.save(output, format="PNG", optimize=True)
        
        result = output.getvalue()
        print(f"âœ… ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ: {len(result)} bytes")
        return result
        
    except Exception as e:
        print(f"âŒ ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        print(f"âŒ ì˜¤ë¥˜ íƒ€ì…: {type(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=400, detail=f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")

def validate_image_file(file: UploadFile) -> bool:
    """ì—…ë¡œë“œëœ íŒŒì¼ì´ ìœ íš¨í•œ ì´ë¯¸ì§€ì¸ì§€ ê²€ì¦"""
    if not file.content_type or not file.content_type.startswith('image/'):
        return False
    
    # ì§€ì›í•˜ëŠ” ì´ë¯¸ì§€ í˜•ì‹
    allowed_types = ['image/png', 'image/jpeg', 'image/jpg', 'image/webp', 'image/svg+xml']
    return file.content_type in allowed_types

def get_logo_hash_from_master(infomax_code: str) -> str:
    """logo_masterì—ì„œ logo_hash ì¡°íšŒ"""
    try:
        master_response = existing_api.query_table("raw_data", "logo_master", {
            "search_column": "infomax_code",
            "search": infomax_code,
            "limit": 1
        })
        
        if isinstance(master_response, dict) and 'data' in master_response and master_response['data']:
            master_data = master_response['data'][0]
            if isinstance(master_data, dict) and 'logo_hash' in master_data:
                return master_data['logo_hash']
        
        # fallback: infomax_codeë¡œ MD5 ìƒì„±
        return hashlib.md5(infomax_code.encode('utf-8')).hexdigest()
        
    except Exception as e:
        print(f"âŒ logo_hash ì¡°íšŒ ì˜¤ë¥˜: {e}")
        # fallback: infomax_codeë¡œ MD5 ìƒì„±
        return hashlib.md5(infomax_code.encode('utf-8')).hexdigest()

# í™˜ê²½ë³€ìˆ˜ ì„¤ì •
def _get_env(key: str, fallback: str | None = None) -> str:
    value = os.getenv(key)
    if value is None or value == "":
        # ì‹¤í–‰ ì¤‘ë‹¨ì„ í”¼í•˜ê¸° ìœ„í•´ ì„ì‹œë¡œ fallback ì‚¬ìš©, ê²½ê³  ì¶œë ¥
        if fallback is not None:
            print(f"âš ï¸  ENV {key} ë¯¸ì„¤ì •: ì„ì‹œê°’ ì‚¬ìš© â†’ {fallback}. .envì— {key}ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
            return fallback
        raise RuntimeError(f"í™˜ê²½ë³€ìˆ˜ {key}ê°€ í•„ìš”í•©ë‹ˆë‹¤. .envì— ì„¤ì •í•˜ì„¸ìš”.")
    return value

# NOTE: ì‹¤í–‰ ì•ˆì •ì„±ì„ ìœ„í•´ ì„ì‹œ fallback ìœ ì§€. ìš´ì˜í™˜ê²½ì—ì„œëŠ” .envì— ë°˜ë“œì‹œ ì„¤ì •.
MINIO_ENDPOINT = _get_env('MINIO_ENDPOINT', 'minio:9000')
MINIO_ACCESS_KEY = _get_env('MINIO_ACCESS_KEY', 'minioadmin')
MINIO_SECRET_KEY = _get_env('MINIO_SECRET_KEY', 'minioadmin123')
MINIO_BUCKET = _get_env('MINIO_BUCKET', 'logos')
EXISTING_API_BASE = _get_env('EXISTING_API_BASE', 'http://10.150.2.150:8004')
LOGO_DEV_DAILY_LIMIT = int(_get_env('LOGO_DEV_DAILY_LIMIT', '5000'))

# MinIO ì—°ê²°
minio_client = Minio(
    MINIO_ENDPOINT,
    access_key=MINIO_ACCESS_KEY,
    secret_key=MINIO_SECRET_KEY,
    secure=False
)

# MinIO ë²„í‚· ìƒì„± (ì—†ìœ¼ë©´ ìƒì„±)
def ensure_bucket_exists():
    """MinIO ë²„í‚·ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ìœ¼ë©´ ìƒì„±"""
    try:
        if not minio_client.bucket_exists(MINIO_BUCKET):
            minio_client.make_bucket(MINIO_BUCKET)
            print(f"âœ… Created MinIO bucket: {MINIO_BUCKET}")
        else:
            print(f"âœ… MinIO bucket exists: {MINIO_BUCKET}")
    except Exception as e:
        print(f"âŒ MinIO bucket creation failed: {e}")

# ì•± ì‹œì‘ ì‹œ ë²„í‚· í™•ì¸
ensure_bucket_exists()

# ì§„í–‰ìƒí™© ëª¨ë‹ˆí„°ë§ ë””ë ‰í† ë¦¬
PROGRESS_DIR = Path(os.getenv('PROGRESS_DIR', 'progress'))
PROGRESS_DIR.mkdir(exist_ok=True)

# ê¸°ì¡´ API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
existing_api = ExistingAPIClient(EXISTING_API_BASE)

# ì¿¼í„° ë§¤ë‹ˆì € í´ë˜ìŠ¤
class QuotaManager:
    """API ì¿¼í„° ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, api_name: str, daily_limit: int):
        self.api_name = api_name
        self.daily_limit = daily_limit
    
    def check_and_consume_quota(self, count: int = 1) -> bool:
        """ì¿¼í„° í™•ì¸ ë° ì†Œëª¨ (ì›ìì  ì—°ì‚°)"""
        try:
            today = date.today()
            
            # í˜„ì¬ ì‚¬ìš©ëŸ‰ ì¡°íšŒ
            current_usage = self._get_current_usage(today)
            
            if current_usage + count > self.daily_limit:
                print(f"âŒ {self.api_name} ì¼ì¼ ì¿¼í„° ì´ˆê³¼: {current_usage}/{self.daily_limit} (ìš”ì²­: {count})")
                return False
            
            # ì¿¼í„° ì†Œëª¨ (upsert ë°©ì‹)
            success = self._consume_quota(today, count)
            if success:
                print(f"âœ… {self.api_name} ì¿¼í„° ì†Œëª¨: {count}ê±´ (ì´ {current_usage + count}/{self.daily_limit})")
            return success
            
        except Exception as e:
            print(f"âŒ ì¿¼í„° í™•ì¸ ì˜¤ë¥˜: {e}")
            return False
    
    def _get_current_usage(self, target_date: date) -> int:
        """í˜„ì¬ ì‚¬ìš©ëŸ‰ ì¡°íšŒ"""
        try:
            response = existing_api.query_table("raw_data", "ext_api_quota", {
                "date_utc": target_date.isoformat(),
                "api_name": self.api_name,
                "limit": 1
            })
            
            if response and 'data' in response and response['data']:
                return response['data'][0].get('used_count', 0)
            return 0
        except Exception as e:
            print(f"âŒ ì‚¬ìš©ëŸ‰ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return 0
    
    def _consume_quota(self, target_date: date, count: int) -> bool:
        """ì¿¼í„° ì†Œëª¨ (upsert)"""
        try:
            # upsert ë°ì´í„° ì¤€ë¹„
            quota_data = {
                "data": {
                    "date_utc": target_date.isoformat(),
                    "api_name": self.api_name,
                    "used_count": count  # ì¦ê°€ëŸ‰
                },
                "conflict_columns": ["date_utc", "api_name"]
            }
            
            # upsert ì‹¤í–‰ (ON CONFLICT ì‹œ used_count += count)
            result = existing_api.upsert_data("raw_data", "ext_api_quota", quota_data)
            return result is not None
            
        except Exception as e:
            print(f"âŒ ì¿¼í„° ì†Œëª¨ ì˜¤ë¥˜: {e}")
            return False

# ì¿¼í„° ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤
logo_dev_quota = QuotaManager("logo_dev", LOGO_DEV_DAILY_LIMIT)

# ë¡œê³  ë°ì´í„° ì €ì¥ í•¨ìˆ˜
def save_logo_data(infomax_code: str, logo_hash: str, file_info: dict) -> bool:
    """ë¡œê³  ë°ì´í„°ë¥¼ DBì— ì €ì¥ (logos -> logo_files ìˆœì„œ)"""
    try:
        # 1. logos í…Œì´ë¸”ì— ë°ì´í„° ì…ë ¥ ë˜ëŠ” ê¸°ì¡´ ë°ì´í„° ì¡°íšŒ
        # ë¨¼ì € ê¸°ì¡´ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
        existing_logo = existing_api.query_table("raw_data", "logos", {
            "search_column": "logo_hash",
            "search": logo_hash,
            "limit": 1
        })
        
        if existing_logo and 'data' in existing_logo and existing_logo['data']:
            # ê¸°ì¡´ ë°ì´í„°ê°€ ìˆìœ¼ë©´ í•´ë‹¹ logo_id ì‚¬ìš©
            logo_id = existing_logo['data'][0]['logo_id']
            print(f"âœ… ê¸°ì¡´ logos ë°ì´í„° ì‚¬ìš©: logo_id={logo_id}, logo_hash={logo_hash}")
        else:
            # ê¸°ì¡´ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
            logo_data = {
                "data": {
                    "logo_hash": logo_hash,
                    "is_deleted": False
                },
                "conflict_columns": ["logo_hash"]
            }
            
            logo_result = existing_api.upsert_data("raw_data", "logos", logo_data)
            if not logo_result or 'data' not in logo_result:
                print(f"âŒ logos í…Œì´ë¸” ì €ì¥ ì‹¤íŒ¨: {infomax_code}")
                return False
            
            logo_id = logo_result['data']['logo_id']
            print(f"âœ… logos í…Œì´ë¸” ì €ì¥ ì„±ê³µ: logo_id={logo_id}, logo_hash={logo_hash}")
        
        # 2. logo_files í…Œì´ë¸”ì— ë°ì´í„° ì…ë ¥
        file_data = {
            "data": {
                "logo_id": logo_id,
                "file_format": file_info["format"],
                "dimension_width": file_info["width"],
                "dimension_height": file_info["height"],
                "file_size": file_info["size"],
                "minio_object_key": file_info["minio_key"],
                "data_source": file_info["source"],
                "upload_type": file_info["upload_type"],
                "is_original": file_info.get("is_original", True)
            },
            "conflict_columns": ["minio_object_key"]
        }
        
        file_result = existing_api.upsert_data("raw_data", "logo_files", file_data)
        if not file_result:
            print(f"âŒ logo_files í…Œì´ë¸” ì €ì¥ ì‹¤íŒ¨: {infomax_code}")
            return False
        
        print(f"âœ… logo_files í…Œì´ë¸” ì €ì¥ ì„±ê³µ: logo_id={logo_id}")
        
        print(f"âœ… ë¡œê³  ë°ì´í„° ì €ì¥ ì™„ë£Œ: {infomax_code}")
        return True
        
    except Exception as e:
        print(f"âŒ ë¡œê³  ë°ì´í„° ì €ì¥ ì˜¤ë¥˜: {e}")
        return False

# ê¸°ì¡´ API í´ë¼ì´ì–¸íŠ¸ëŠ” ì´ë¯¸ ìœ„ì—ì„œ ì •ì˜ë¨
# crawler = LogoCrawler()  # ì„ì‹œë¡œ ë¹„í™œì„±í™”

def generate_logo_hash(infomax_code: str, source: str = "tradingview") -> str:
    """ë¡œê³  í•´ì‹œ ìƒì„±"""
    return hashlib.md5(f"{source}_{infomax_code}".encode()).hexdigest()

@app.get("/")
# @limiter.limit("10/minute")  # ì„ì‹œ ë¹„í™œì„±í™”
async def root(request: Request):
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    logger.info(f"Root endpoint accessed from {request.client.host}")
    return {
        "message": "Logo Management System - Prototype API",
        "version": "1.0.0",
        "docs": "/docs",
        "status": "running",
        "existing_api": EXISTING_API_BASE
    }

@app.get("/api/v1/test")
async def test_endpoint():
    """í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    print("ğŸ”ğŸ”ğŸ” TEST ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œ")
    return {"status": "test", "message": "Test endpoint working"}

@app.get("/api/v1/logos/search")
async def search_logos(
    fs_regional_id: Optional[str] = None,
    fs_entity_id: Optional[int] = None,
    has_logo: bool = True,
    limit: int = 100
):
    """ë¡œê³  ì¡´ì¬ ì—¬ë¶€ ê²€ìƒ‰ - ê¸°ì¡´ APIë¥¼ í†µí•´ ë°ì´í„° ì¡°íšŒ"""
    
    try:
        # ê¸°ì¡´ APIë¥¼ í†µí•´ master ë°ì´í„° ì¡°íšŒ (logo_master ë·° ì‚¬ìš©)
        master_params = {"limit": limit}
        if fs_regional_id:
            master_params["fs_regional_id"] = fs_regional_id
        if fs_entity_id:
            master_params["fs_entity_id"] = fs_entity_id
        
        master_response = existing_api.query_table("raw_data", "logo_master", master_params)
        
        # API ì‘ë‹µ êµ¬ì¡° í™•ì¸
        if isinstance(master_response, dict) and 'data' in master_response:
            master_data = master_response['data']
        else:
            master_data = master_response if master_response else []
        
        if not master_data:
            return {
                "count": 0,
                "has_logo": has_logo,
                "results": []
            }
        
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì²˜ìŒ 3ê°œë§Œ ì²˜ë¦¬
        results = []
        for i, master_info in enumerate(master_data[:3]):
            print(f"ğŸ” ì²˜ë¦¬ ì¤‘: {i} - {type(master_info)} - {master_info}")
            
            # master_infoê°€ ë”•ì…”ë„ˆë¦¬ì¸ì§€ í™•ì¸
            if not isinstance(master_info, dict):
                print(f"âš ï¸ master_infoê°€ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹˜: {type(master_info)} - {master_info}")
                continue
                
            infomax_code = master_info.get("infomax_code")
            if not infomax_code:
                print(f"âš ï¸ infomax_codeê°€ ì—†ìŒ: {master_info}")
                continue
            
            # logos í…Œì´ë¸”ì—ì„œ í•´ë‹¹ infomax_codeì˜ ë¡œê³  ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            logo_response = existing_api.query_table("raw_data", "logos", {
                "logo_hash": master_info.get("logo_hash"),
                "is_deleted": False,
                "limit": 1
            })
            
            logo_exists = False
            if isinstance(logo_response, dict) and 'data' in logo_response:
                logo_data = logo_response['data']
                logo_exists = len(logo_data) > 0
            elif logo_response:
                logo_exists = len(logo_response) > 0
            
            # has_logo í•„í„° ì ìš©
            if has_logo and not logo_exists:
                continue
            elif not has_logo and logo_exists:
                continue
            
            results.append({
                "infomax_code": infomax_code,
                "terminal_code": master_info.get("terminal_code"),
                "english_name": master_info.get("english_name"),
                "fs_regional_id": master_info.get("fs_regional_id"),
                "fs_entity_id": master_info.get("fs_entity_id"),
                "has_logo": logo_exists,
                "logo_hash": master_info.get("logo_hash")
            })
        
        return {
            "count": len(results),
            "has_logo": has_logo,
            "results": results
        }
        
    except Exception as e:
        print(f"âŒ ë¡œê³  ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"Search failed: {e}")

@app.get("/api/v1/logos/{infomax_code}")
# @limiter.limit("30/minute")  # ì„ì‹œ ë¹„í™œì„±í™”
async def get_logo(request: Request, infomax_code: str, format: str = "png", size: int = 300):
    # í¬ê¸° ë§¤í•‘: 300px -> 256px (ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í¬ê¸°)
    if size == 300:
        size = 256
    """ë¡œê³  ì¡°íšŒ - ì´ë¯¸ì§€ ìŠ¤íŠ¸ë¦¬ë° (ë©”íƒ€ ì¡°íšŒ â†’ MinIO ê°ì²´ ë°”ì´ë„ˆë¦¬ ë°˜í™˜)"""
    logger.info(f"Logo request: {infomax_code}, format={format}, size={size} from {request.client.host}")
    try:
        print(f"ğŸ” get_logo í•¨ìˆ˜ í˜¸ì¶œë¨: infomax_code={infomax_code}, format={format}, size={size}")
        
        # 1. logo_hash ì¡°íšŒ ë˜ëŠ” ìƒì„± (ë””ë²„ê·¸ í”Œë¡œìš°ì™€ ë™ì¼)
        logo_hash = get_logo_hash_from_master(infomax_code)
        print(f"ğŸ” logo_hash: {logo_hash}")
        
        # 2. logos í…Œì´ë¸”ì—ì„œ ë¡œê³  ì •ë³´ ì¡°íšŒ
        print(f"ğŸ” logos í…Œì´ë¸” ì¡°íšŒ ì‹œì‘: logo_hash={logo_hash}")
        logo_response = existing_api.query_table("raw_data", "logos", {
            "search_column": "logo_hash",
            "search": logo_hash,
            "is_deleted": False,
            "limit": 1
        })
        print(f"ğŸ” logos í…Œì´ë¸” ì‘ë‹µ: {logo_response}")
        
        if not logo_response or not logo_response.get('data'):
            print(f"âŒ logos í…Œì´ë¸”ì—ì„œ {logo_hash}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            raise HTTPException(status_code=404, detail="Logo not found in database")
        
        logo_data = logo_response['data'][0]
        logo_id = logo_data.get('logo_id')
        print(f"ğŸ” ì¡°íšŒëœ logo_id: {logo_id}")
        
        # 3. logo_files í…Œì´ë¸”ì—ì„œ í•´ë‹¹ logo_idì˜ íŒŒì¼ë“¤ ì¡°íšŒ
        print(f"ğŸ” logo_files í…Œì´ë¸” ì¡°íšŒ ì‹œì‘: logo_id={logo_id}")
        file_response = existing_api.query_table("raw_data", "logo_files", {
            "page": 1,
            "size": 100
        })
        print(f"ğŸ” logo_files í…Œì´ë¸” ì‘ë‹µ: {file_response}")
        
        if not file_response or not file_response.get('data'):
            print(f"âŒ logo_files í…Œì´ë¸”ì—ì„œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            raise HTTPException(status_code=404, detail="Logo files not found")
        
        all_files = file_response['data']
        print(f"ğŸ” ì „ì²´ íŒŒì¼ ìˆ˜: {len(all_files)}ê°œ")
        
        # 4. ì¡°ê±´ì— ë§ëŠ” íŒŒì¼ ì°¾ê¸°
        found_file = None
        for f in all_files:
            if (f.get('logo_id') == logo_id and 
                f.get('file_format') == format and 
                f.get('dimension_width') == size and
                str(f.get('minio_object_key','')).startswith(logo_hash)):
                found_file = f
                print(f"ğŸ” ì¡°ê±´ì— ë§ëŠ” íŒŒì¼ ë°œê²¬: {f.get('minio_object_key')}")
                break
        
        if not found_file:
            print(f"âŒ ì¡°ê±´ì— ë§ëŠ” íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: logo_id={logo_id}, format={format}, size={size}")
            # ì‚¬ìš© ê°€ëŠ¥í•œ íŒŒì¼ë“¤ ì¶œë ¥
            available_files = [f for f in all_files if f.get('logo_id') == logo_id]
            print(f"ğŸ” ì‚¬ìš© ê°€ëŠ¥í•œ íŒŒì¼ë“¤: {[f.get('minio_object_key') for f in available_files]}")
            raise HTTPException(status_code=404, detail="Logo file not found")
        
        file_info = found_file
        object_key = file_info.get('minio_object_key')
        if not object_key:
            raise HTTPException(status_code=404, detail="Object key not found")
        
        print(f"ğŸ” ìµœì¢… ì„ íƒëœ íŒŒì¼: {object_key}")
        
        # 5. MinIOì—ì„œ íŒŒì¼ ì¡°íšŒ
        try:
            minio_client.stat_object(MINIO_BUCKET, object_key)
            print(f"âœ… MinIO ê°ì²´ ì¡´ì¬ í™•ì¸: {object_key}")
        except Exception as e:
            print(f"âŒ MinIO ê°ì²´ ì—†ìŒ: {e}")
            # ì‚¬ìš© ê°€ëŠ¥í•œ ê°ì²´ë“¤ ì¶œë ¥
            try:
                print(f"ğŸ” prefix ëª©ë¡: {logo_hash}")
                for o in minio_client.list_objects(MINIO_BUCKET, prefix=logo_hash):
                    print(f"  - {o.object_name}")
            except Exception as e2:
                print(f"âŒ list_objects ì‹¤íŒ¨: {e2}")
            raise HTTPException(status_code=404, detail=f"MinIO object not found: {object_key}")
        
        # 6. íŒŒì¼ ìŠ¤íŠ¸ë¦¬ë° ë°˜í™˜
        obj = minio_client.get_object(MINIO_BUCKET, object_key)
        content_type = f"image/{format.lower()}"
        data = obj.read()
        obj.close()
        obj.release_conn()
        
        print(f"âœ… ë¡œê³  ë°˜í™˜ ì™„ë£Œ: {len(data)} bytes")
        return Response(content=data, media_type=content_type)
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ get_logo ì˜¤ë¥˜: {e}")
        import traceback
        print(f"ğŸ“‹ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/crawl/test")
async def crawl_test():
    """í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    print("ğŸ”ğŸ”ğŸ” CRAWL TEST ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œ")
    return {"status": "test", "message": "Crawl test endpoint working"}

@app.get("/api/v1/logo-info")
async def get_logo_by_criteria(
    infomax_code: Optional[str] = None,
    fs_regional_id: Optional[str] = None,
    fs_entity_id: Optional[int] = None,
    format: str = "png",
    size: int = 300
):
    """ì„œë¹„ìŠ¤ì—ì„œ ì‚¬ìš©í•  ë¡œê³  ì¡°íšŒ API - ê¸°ì¡´ APIë¥¼ í†µí•´ ë°ì´í„° ì¡°íšŒ"""
    
    print(f"ğŸ” get_logo_by_criteria í•¨ìˆ˜ í˜¸ì¶œë¨: infomax_code={infomax_code}, fs_regional_id={fs_regional_id}, fs_entity_id={fs_entity_id}")
    # í¬ê¸° ë§¤í•‘: 300px -> 256px (ì‹¤ì œ ì €ì¥ëœ í‘œì¤€ í¬ê¸°ì— ë§ì¶¤)
    if size == 300:
        size = 256
    
    if not any([infomax_code, fs_regional_id, fs_entity_id]):
        raise HTTPException(status_code=400, detail="At least one search criteria required")
    
    try:
        # ê¸°ì¡´ APIë¥¼ í†µí•´ master ë°ì´í„° ì¡°íšŒ (logo_master ë·° ì‚¬ìš©)
        master_params = {"limit": 1}
        if infomax_code:
            master_params["infomax_code"] = infomax_code
        if fs_regional_id:
            master_params["fs_regional_id"] = fs_regional_id
        if fs_entity_id:
            master_params["fs_entity_id"] = fs_entity_id
        
        master_response = existing_api.query_table("raw_data", "logo_master", master_params)
        
        # API ì‘ë‹µ êµ¬ì¡° í™•ì¸
        if isinstance(master_response, dict) and 'data' in master_response:
            master_data = master_response['data']
        else:
            master_data = master_response if master_response else []
        
        if not master_data or len(master_data) == 0:
            # ë§ˆìŠ¤í„°ì— ì—†ì„ ê²½ìš°: infomax_code MD5 ê¸°ë°˜ fallback ì¡°íšŒ
            if infomax_code:
                fallback_hash = hashlib.md5(infomax_code.encode('utf-8')).hexdigest()
                logo_response = existing_api.query_table("raw_data", "logos", {
                    "logo_hash": fallback_hash,
                    "is_deleted": False,
                    "limit": 1
                })
                if isinstance(logo_response, dict) and logo_response.get('data'):
                    logo_data = logo_response['data']
                    file_response = existing_api.query_table("raw_data", "logo_files", {
                        "page": 1,
                        "size": 100
                    })
                    if isinstance(file_response, dict) and file_response.get('data'):
                        all_files = file_response['data']
                        # í´ë¼ì´ì–¸íŠ¸ì—ì„œ í•„í„°ë§
                        found_file = None
                        for f in all_files:
                            if (f.get('logo_id') == logo_data[0]["logo_id"] and 
                                f.get('file_format') == format and 
                                f.get('dimension_width') == size and
                                str(f.get('minio_object_key','')).startswith(logo_data[0]["logo_hash"])):
                                found_file = f
                                break
                        
                        if not found_file:
                            raise HTTPException(status_code=404, detail="Logo file not found")
                        
                        file_info = found_file
                        return {
                            "infomax_code": infomax_code,
                            "terminal_code": None,
                            "english_name": None,
                            "fs_regional_id": None,
                            "fs_entity_id": None,
                            "logo_hash": fallback_hash,
                            "logo_exists": True,
                            "file_info": {
                                "file_format": file_info.get('file_format'),
                                "file_size": file_info.get('file_size'),
                                "data_source": file_info.get('data_source'),
                                "upload_type": file_info.get('upload_type'),
                                "minio_object_key": file_info.get('minio_object_key'),
                                "dimension_width": file_info.get('dimension_width'),
                                "dimension_height": file_info.get('dimension_height'),
                                "quality": file_info.get('quality')
                            },
                            "logo_info": {
                                "logo_id": logo_data[0].get('logo_id'),
                                "is_deleted": logo_data[0].get('is_deleted'),
                                "created_at": logo_data[0].get('created_at'),
                                "updated_at": logo_data[0].get('updated_at')
                            }
                        }
            raise HTTPException(status_code=404, detail="Ticker not found in master data")
        
        master_info = master_data[0]
        infomax_code = master_info.get("infomax_code")
        
        # master_dataì—ì„œ logo_hash ì¡°íšŒ
        logo_hash = master_info.get("logo_hash")
        if not logo_hash:
            raise HTTPException(status_code=404, detail="Logo hash not found in master data")
        
        # logos í…Œì´ë¸”ì—ì„œ ë¡œê³  ì •ë³´ ì¡°íšŒ (ê²€ìƒ‰ íŒŒë¼ë¯¸í„° ì‚¬ìš© í›„ í´ë¼ì´ì–¸íŠ¸ í•„í„°)
        logo_response = existing_api.query_table("raw_data", "logos", {
            "page": 1,
            "search_column": "logo_hash",
            "search": logo_hash
        })
        if isinstance(logo_response, dict) and 'data' in logo_response:
            candidates = logo_response['data'] or []
        else:
            candidates = logo_response or []
        logo_data = [r for r in candidates if isinstance(r, dict) and r.get('logo_hash') == logo_hash and r.get('is_deleted') is False]
        if not logo_data:
            raise HTTPException(status_code=404, detail="Logo not found")
        
        # logo_files í…Œì´ë¸”ì—ì„œ íŒŒì¼ ì •ë³´ ì¡°íšŒ (ê²€ìƒ‰ íŒŒë¼ë¯¸í„° ì‚¬ìš© í›„ í´ë¼ì´ì–¸íŠ¸ í•„í„°)
        files_response = existing_api.query_table("raw_data", "logo_files", {
            "page": 1,
            "search_column": "logo_id",
            "search": str(logo_data[0]["logo_id"])
        })
        if isinstance(files_response, dict) and 'data' in files_response:
            files = files_response['data'] or []
        else:
            files = files_response or []
        # ë™ì¼ í•´ì‹œ prefixë§Œ ì‚¬ìš©
        files = [f for f in files if isinstance(f, dict) and str(f.get('minio_object_key','')).startswith(logo_hash)]
        # í›„ë³´ ì„ íƒ: ì •í™• ë§¤ì¹­ â†’ í¬ë§·ë§Œ ë§¤ì¹­ â†’ ì²« ë²ˆì§¸
        file_info = None
        for f in files:
            if f.get('file_format') == format and f.get('dimension_width') == size:
                file_info = f; break
        if not file_info:
            for f in files:
                if f.get('file_format') == format:
                    file_info = f; break
        if not file_info and files:
            file_info = files[0]
        if not file_info:
            raise HTTPException(status_code=404, detail="Logo file not found")
        
        # JSON ë©”íƒ€ë°ì´í„° ë°˜í™˜
        return {
            "infomax_code": infomax_code,
            "terminal_code": master_info.get("terminal_code"),
            "english_name": master_info.get("english_name"),
            "fs_regional_id": master_info.get("fs_regional_id"),
            "fs_entity_id": master_info.get("fs_entity_id"),
            "logo_hash": logo_hash,
            "logo_exists": True,
            "file_info": {
                "file_format": file_info.get('file_format'),
                "file_size": file_info.get('file_size'),
                "data_source": file_info.get('data_source'),
                "upload_type": file_info.get('upload_type'),
                "minio_object_key": file_info.get('minio_object_key'),
                "dimension_width": file_info.get('dimension_width'),
                "dimension_height": file_info.get('dimension_height'),
                "quality": file_info.get('quality')
            },
            "logo_info": {
                "logo_id": logo_data[0].get('logo_id'),
                "is_deleted": logo_data[0].get('is_deleted'),
                "created_at": logo_data[0].get('created_at'),
                "updated_at": logo_data[0].get('updated_at')
            }
        }
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/v1/progress/{job_id}")
async def get_progress(job_id: str):
    """ì‘ì—… ì§„í–‰ìƒí™© ì¡°íšŒ"""
    progress_file = PROGRESS_DIR / f"{job_id}.json"
    
    if not progress_file.exists():
        raise HTTPException(status_code=404, detail="Job not found")
    
    try:
        with open(progress_file, 'r', encoding='utf-8') as f:
            progress_data = json.load(f)
        
        return progress_data
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/stats")
async def get_stats():
    """ì‹œìŠ¤í…œ í†µê³„ ì¡°íšŒ - ê¸°ì¡´ APIë¥¼ í†µí•´ ë°ì´í„° ì¡°íšŒ"""
    try:
        # ì „ì²´ ë¡œê³  ìˆ˜
        logos_response = existing_api.query_table("raw_data", "logos", {
            "is_deleted": False,
            "limit": 1000  # í†µê³„ìš©ìœ¼ë¡œ ì¶©ë¶„í•œ ìˆ˜
        })
        
        # API ì‘ë‹µ êµ¬ì¡° í™•ì¸
        if isinstance(logos_response, dict) and 'data' in logos_response:
            total_logos_data = logos_response['data']
            total_logos = len(total_logos_data)
        else:
            total_logos_data = logos_response if logos_response else []
            total_logos = len(total_logos_data)
        
        # ì˜¤ëŠ˜ ìˆ˜ì§‘ëœ ë¡œê³  ìˆ˜ (ê°„ë‹¨í•œ í•„í„°ë§)
        today_logos = 0
        if total_logos_data and isinstance(total_logos_data, list):
            today = datetime.now().strftime('%Y-%m-%d')
            for logo in total_logos_data:
                if isinstance(logo, dict) and logo.get('created_at', '').startswith(today):
                    today_logos += 1
        
        # ë°ì´í„° ì†ŒìŠ¤ë³„ í†µê³„
        source_stats = {}
        if total_logos_data and isinstance(total_logos_data, list):
            for logo in total_logos_data:
                if isinstance(logo, dict):
                    logo_id = logo.get('logo_id')
                    if logo_id:
                        file_response = existing_api.query_table("raw_data", "logo_files", {
                            "page": 1,
                            "size": 100
                        })
                        
                        # API ì‘ë‹µ êµ¬ì¡° í™•ì¸
                        if isinstance(file_response, dict) and 'data' in file_response:
                            file_data = file_response['data']
                        else:
                            file_data = file_response if file_response else []
                        
                        if file_data and isinstance(file_data, list):
                            for file_info in file_data:
                                if isinstance(file_info, dict):
                                    data_source = file_info.get('data_source', 'unknown')
                                    source_stats[data_source] = source_stats.get(data_source, 0) + 1
        
        return {
            "total_logos": total_logos,
            "today_logos": today_logos,
            "source_stats": source_stats,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    try:
        # MinIO ì—°ê²° í™•ì¸
        minio_client.bucket_exists(MINIO_BUCKET)
        
        # ê¸°ì¡´ API ì—°ê²° í™•ì¸
        existing_api_status = "connected"
        try:
            response = requests.get(f"{EXISTING_API_BASE}/health", timeout=5)
            if response.status_code != 200:
                existing_api_status = "error"
        except:
            existing_api_status = "disconnected"
        
        return {
            "status": "healthy",
            "minio": "connected",
            "existing_api": existing_api_status,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/debug/test-api")
async def debug_test_api():
    """ê¸°ì¡´ API ì—°ê²° ë””ë²„ê¹…"""
    try:
        # ê¸°ì¡´ API í…ŒìŠ¤íŠ¸
        test_response = existing_api.query_table("raw_data", "logo_master", {"limit": 1})
        
        return {
            "test_response_type": str(type(test_response)),
            "test_response": test_response,
            "is_dict": isinstance(test_response, dict),
            "has_data": isinstance(test_response, dict) and 'data' in test_response if isinstance(test_response, dict) else False
        }
    except Exception as e:
        return {
            "error": str(e),
            "error_type": str(type(e))
        }

@app.post("/api/v1/debug/test-insert")
async def debug_test_insert():
    """ë°ì´í„° ì…ë ¥ í…ŒìŠ¤íŠ¸ - logos, logo_files í…Œì´ë¸”"""
    try:
        # í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° ì¤€ë¹„
        test_infomax_code = "TEST:DEBUG"
        test_logo_hash = generate_logo_hash(test_infomax_code)
        
        # 1. logos í…Œì´ë¸”ì— ë°ì´í„° ì…ë ¥ í…ŒìŠ¤íŠ¸
        logo_data = {
            "data": {
            "logo_hash": test_logo_hash,
            "is_deleted": False
            },
            "conflict_columns": ["logo_hash"]
        }
        # ê¸°ì¡´ APIë¥¼ í†µí•´ logos í…Œì´ë¸”ì— ë°ì´í„° ì…ë ¥ (upsert)
        logo_insert_response = existing_api.upsert_data("raw_data", "logos", logo_data)
        logo_id = None
        if isinstance(logo_insert_response, dict):
            # ì˜ˆìƒ ë°˜í™˜: { data: { logo_id: ..., logo_hash: ... } } í˜¹ì€ ìœ ì‚¬ í˜•íƒœ
            logo_id = (
                logo_insert_response.get("data", {}).get("logo_id")
                if isinstance(logo_insert_response.get("data"), dict)
                else logo_insert_response.get("logo_id")
            )
        
        # logo_idê°€ ì‘ë‹µì— ì—†ìœ¼ë©´ ì¡°íšŒë¡œ í™•ì¸
        if not logo_id:
            check = existing_api.query_table("raw_data", "logos", {"logo_hash": test_logo_hash, "limit": 1})
            if isinstance(check, dict) and check.get("data"):
                logo_id = check["data"][0].get("logo_id")
        
        # 2. logo_files í…Œì´ë¸”ì— ë°ì´í„° ì…ë ¥ í…ŒìŠ¤íŠ¸
        file_payload = {
            "data": {
                "logo_id": logo_id or 0,
            "file_format": "png",
                "data_source": "manual",
                "upload_type": "manual",
                "dimension_width": 256,
                "dimension_height": 256,
            "file_size": 1024,
            "minio_object_key": f"test/{test_logo_hash}_256.png",
                "is_original": True
            },
            "conflict_columns": ["minio_object_key"]
        }
        file_insert_response = existing_api.upsert_data("raw_data", "logo_files", file_payload)
        
        return {
            "status": "success",
            "logo_insert": logo_insert_response,
            "file_insert": file_insert_response,
            "test_data": {
                "infomax_code": test_infomax_code,
                "logo_hash": test_logo_hash
            }
        }
        
    except Exception as e:
        return {
            "status": "error",
            "error": str(e),
            "error_type": str(type(e))
        }


@app.get("/api/v1/debug/files")
async def debug_list_files(infomax_code: str):
    """ì§€ì • ì¢…ëª©ì˜ logo_hash, logos, logo_files ëª©ë¡ ë””ë²„ê·¸ ì¶œë ¥"""
    try:
        # 1) master â†’ logo_hash
        master = existing_api.query_table("raw_data", "logo_master", {"infomax_code": infomax_code, "limit": 1})
        if not isinstance(master, dict) or not master.get("data"):
            return {"status": "not_found_in_master", "infomax_code": infomax_code}
        logo_hash = master["data"][0].get("logo_hash")
        # 2) logos by logo_hash
        logos_resp = existing_api.query_table("raw_data", "logos", {"page": 1, "search_column": "logo_hash", "search": logo_hash})
        logos = logos_resp.get("data", []) if isinstance(logos_resp, dict) else (logos_resp or [])
        if not logos:
            return {"status": "no_logos", "logo_hash": logo_hash}
        logo_id = logos[0].get("logo_id")
        # 3) files by logo_id
        files_resp = existing_api.query_table("raw_data", "logo_files", {"page": 1, "size": 1000})
        files = files_resp.get("data", []) if isinstance(files_resp, dict) else (files_resp or [])
        return {
            "status": "ok",
            "infomax_code": infomax_code,
            "logo_hash": logo_hash,
            "logo_id": logo_id,
            "files_count": len([f for f in files if isinstance(f, dict) and f.get('logo_id') == logo_id]),
            "files": [f for f in files if isinstance(f, dict) and f.get('logo_id') == logo_id],
        }
    except Exception as e:
        return {"status": "error", "error": str(e)}

@app.get("/api/v1/debug/minio")
async def debug_minio_check(object_key: str):
    """MinIO ê°ì²´ ì¡´ì¬ ì—¬ë¶€ ë° ë©”íƒ€ë°ì´í„° í™•ì¸"""
    try:
        # MinIO ê°ì²´ ì¡´ì¬ í™•ì¸
        stat = minio_client.stat_object(MINIO_BUCKET, object_key)
        return {
            "status": "exists",
            "object_key": object_key,
            "bucket": MINIO_BUCKET,
            "size": stat.size,
            "etag": stat.etag,
            "last_modified": stat.last_modified.isoformat() if stat.last_modified else None,
            "content_type": stat.content_type
        }
    except Exception as e:
        # ê°ì²´ ëª©ë¡ìœ¼ë¡œ í™•ì¸
        try:
            objects = list(minio_client.list_objects(MINIO_BUCKET, prefix=object_key.split('_')[0]))
            return {
                "status": "not_found",
                "object_key": object_key,
                "bucket": MINIO_BUCKET,
                "error": str(e),
                "available_objects": [obj.object_name for obj in objects[:10]]
            }
        except Exception as e2:
            return {
                "status": "error",
                "object_key": object_key,
                "bucket": MINIO_BUCKET,
                "error": str(e),
                "list_error": str(e2)
            }

@app.get("/api/v1/crawl/status/{job_id}")
async def get_crawl_status(job_id: str):
    """í¬ë¡¤ë§ ì‘ì—… ìƒíƒœ í™•ì¸"""
    try:
        # ì§„í–‰ìƒí™© íŒŒì¼ ê²½ë¡œ
        progress_file = PROGRESS_DIR / f"{job_id}.json"
        
        if not progress_file.exists():
            return {
                "status": "not_found",
                "job_id": job_id,
                "message": "Job not found"
            }
        
        # ì§„í–‰ìƒí™© íŒŒì¼ ì½ê¸°
        with open(progress_file, 'r', encoding='utf-8') as f:
            progress_data = json.load(f)
        
        return {
            "status": "found",
            "job_id": job_id,
            "progress": progress_data
        }
        
    except Exception as e:
        return {
            "status": "error",
            "job_id": job_id,
            "error": str(e)
        }

@app.get("/api/v1/crawl/jobs")
async def list_crawl_jobs():
    """ëª¨ë“  í¬ë¡¤ë§ ì‘ì—… ëª©ë¡ ì¡°íšŒ"""
    try:
        jobs = []
        for progress_file in PROGRESS_DIR.glob("*.json"):
            try:
                with open(progress_file, 'r', encoding='utf-8') as f:
                    progress_data = json.load(f)
                
                jobs.append({
                    "job_id": progress_file.stem,
                    "status": progress_data.get("status", "unknown"),
                    "created_at": progress_data.get("created_at"),
                    "total_items": progress_data.get("total_items", 0),
                    "processed_items": progress_data.get("processed_items", 0),
                    "successful_items": progress_data.get("successful_items", 0),
                    "failed_items": progress_data.get("failed_items", 0)
                })
            except Exception as e:
                print(f"âš ï¸ ì§„í–‰ìƒí™© íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {progress_file} - {e}")
                continue
        
        # ìƒì„± ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ìµœì‹ ìˆœ)
        jobs.sort(key=lambda x: x.get("created_at") or "", reverse=True)
        
        return {
            "status": "success",
            "total_jobs": len(jobs),
            "jobs": jobs
        }
        
    except Exception as e:
        return {
            "status": "error",
            "error": str(e)
        }

@app.get("/api/v1/debug/logo-flow")
async def debug_logo_flow(infomax_code: str):
    """ë¡œê³  ì¡°íšŒ í”Œë¡œìš° ì „ì²´ ë””ë²„ê¹…"""
    try:
        result = {"infomax_code": infomax_code, "steps": []}
        
        # 1. master_data ì¡°íšŒ
        master_response = existing_api.query_table("raw_data", "logo_master", {
            "infomax_code": infomax_code,
            "limit": 1
        })
        result["steps"].append({
            "step": "master_query",
            "response": master_response,
            "success": isinstance(master_response, dict) and master_response.get('data')
        })
        
        # 2. logo_hash ì¶”ì¶œ
        logo_hash = None
        if isinstance(master_response, dict) and master_response.get('data'):
            master_data = master_response['data'][0]
            logo_hash = master_data.get('logo_hash')
        
        if not logo_hash:
            logo_hash = hashlib.md5(infomax_code.encode('utf-8')).hexdigest()
            result["steps"].append({
                "step": "logo_hash_fallback",
                "logo_hash": logo_hash,
                "reason": "not_found_in_master"
            })
        else:
            result["steps"].append({
                "step": "logo_hash_from_master",
                "logo_hash": logo_hash
            })
        
        # 3. logos í…Œì´ë¸” ì¡°íšŒ
        logos_response = existing_api.query_table("raw_data", "logos", {
            "search_column": "logo_hash",
            "search": logo_hash,
            "is_deleted": False,
            "limit": 1
        })
        result["steps"].append({
            "step": "logos_query",
            "response": logos_response,
            "success": isinstance(logos_response, dict) and logos_response.get('data')
        })
        
        # 4. logo_files í…Œì´ë¸” ì¡°íšŒ
        if isinstance(logos_response, dict) and logos_response.get('data'):
            logo_id = logos_response['data'][0]['logo_id']
            files_response = existing_api.query_table("raw_data", "logo_files", {
                "page": 1,
                "size": 1000
            })
            result["steps"].append({
                "step": "logo_files_query",
                "logo_id": logo_id,
                "response": files_response,
                "success": isinstance(files_response, dict) and files_response.get('data')
            })
            
            # 5. MinIO ê°ì²´ í™•ì¸
            if isinstance(files_response, dict) and files_response.get('data'):
                files = files_response['data']
                for f in files:
                    if f.get('minio_object_key'):
                        try:
                            stat = minio_client.stat_object(MINIO_BUCKET, f['minio_object_key'])
                            result["steps"].append({
                                "step": "minio_check",
                                "object_key": f['minio_object_key'],
                                "exists": True,
                                "size": stat.size
                            })
                        except Exception as e:
                            result["steps"].append({
                                "step": "minio_check",
                                "object_key": f['minio_object_key'],
                                "exists": False,
                                "error": str(e)
                            })
        
        return result
        
    except Exception as e:
        return {"status": "error", "error": str(e)}

@app.post("/api/v1/debug/seed-file")
async def debug_seed_file(infomax_code: str, size: int = 256, format: str = "png"):
    """í…ŒìŠ¤íŠ¸ìš© íŒŒì¼ì„ ì„œë²„ì—ì„œ ìƒì„±í•˜ì—¬ MinIOì™€ DBì— ì €ì¥"""
    try:
        # master â†’ logo_hash
        master = existing_api.query_table("raw_data", "logo_master", {"infomax_code": infomax_code, "limit": 1})
        if not isinstance(master, dict) or not master.get("data"):
            raise HTTPException(status_code=404, detail="infomax_code not found in master")
        logo_hash = master["data"][0].get("logo_hash")

        # ê°„ë‹¨ ì´ë¯¸ì§€ ìƒì„±
        img = Image.new("RGB", (size, size), color=(173, 216, 230))
        buffer = io.BytesIO()
        fmt = format.upper()
        if fmt == "WEBP":
            img.save(buffer, format="WEBP", quality=88)
        elif fmt in ("JPG", "JPEG"):
            img.save(buffer, format="JPEG", quality=88)
        else:
            img.save(buffer, format="PNG", optimize=True)
        data = buffer.getvalue()

        # MinIO ì—…ë¡œë“œ
        object_key = f"{logo_hash}_{size}.{format.lower()}"
        minio_client.put_object(
            MINIO_BUCKET,
            object_key,
            io.BytesIO(data),
            length=len(data),
            content_type=f"image/{format.lower()}"
        )

        # logos upsert ë³´ì¥
        logo_upsert = existing_api.upsert_data("raw_data", "logos", {
            "data": {"logo_hash": logo_hash, "is_deleted": False},
            "conflict_columns": ["logo_hash"]
        })
        if isinstance(logo_upsert, dict):
            logo_id = (
                logo_upsert.get("data", {}).get("logo_id")
                if isinstance(logo_upsert.get("data"), dict)
                else logo_upsert.get("logo_id")
            )
        else:
            logo_id = None
        if not logo_id:
            check = existing_api.query_table("raw_data", "logos", {"page": 1, "search_column": "logo_hash", "search": logo_hash})
            if isinstance(check, dict) and check.get("data"):
                logo_id = check["data"][0].get("logo_id")

        if not logo_id:
            raise HTTPException(status_code=500, detail="Failed to ensure logo record")

        # logo_files upsert
        file_payload = {
            "data": {
                "logo_id": logo_id,
                "file_format": format.lower(),
                "data_source": "manual",
                "upload_type": "manual",
                "dimension_width": size,
                "dimension_height": size,
                "file_size": len(data),
                "minio_object_key": object_key,
                "is_original": True
            },
            "conflict_columns": ["minio_object_key"]
        }
        file_upsert = existing_api.upsert_data("raw_data", "logo_files", file_payload)

        return {
            "status": "seeded",
            "infomax_code": infomax_code,
            "logo_hash": logo_hash,
            "logo_id": logo_id,
            "object_key": object_key,
            "bytes": len(data),
            "file_upsert": file_upsert
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ê¸°ì¡´ API ì—°ë™ ì—”ë“œí¬ì¸íŠ¸ë“¤
@app.get("/api/v1/existing/schemas")
async def get_existing_schemas():
    """ê¸°ì¡´ APIì—ì„œ ìŠ¤í‚¤ë§ˆ ëª©ë¡ ì¡°íšŒ"""
    try:
        response = requests.get(f"{EXISTING_API_BASE}/api/schemas")
        if response.status_code == 200:
            return response.json()
        else:
            raise HTTPException(status_code=response.status_code, detail="Failed to fetch schemas")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/existing/tables/{schema}")
async def get_existing_tables(schema: str):
    """ê¸°ì¡´ APIì—ì„œ í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ"""
    try:
        response = requests.get(f"{EXISTING_API_BASE}/api/schemas/{schema}/tables")
        if response.status_code == 200:
            return response.json()
        else:
            raise HTTPException(status_code=response.status_code, detail="Failed to fetch tables")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/existing/query/{schema}/{table_name}")
async def query_existing_table(schema: str, table_name: str, page: int = 1, search_column: str = None, search: str = None):
    """ê¸°ì¡´ APIë¥¼ í†µí•´ í…Œì´ë¸” ì¿¼ë¦¬ (í˜ì´ì§€ë„¤ì´ì…˜ ë°©ì‹)"""
    try:
        params = {"page": page}
        if search_column and search:
            params.update({
                "search_column": search_column,
                "search": search
            })
        
        response = requests.get(
            f"{EXISTING_API_BASE}/api/schemas/{schema}/tables/{table_name}/query",
            params=params
        )
        if response.status_code == 200:
            return response.json()
        else:
            raise HTTPException(status_code=response.status_code, detail="Failed to query table")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# í¬ë¡¤ë§ ê´€ë ¨ ì—”ë“œí¬ì¸íŠ¸
class CrawlSingleRequest(BaseModel):
    infomax_code: str
    ticker: str
    api_domain: Optional[str] = None

@app.post("/api/v1/crawl/single")
# @limiter.limit("5/minute")  # ì„ì‹œ ë¹„í™œì„±í™”
async def crawl_single_logo(request: Request, crawl_request: CrawlSingleRequest):
    """ë‹¨ì¼ ë¡œê³  í¬ë¡¤ë§ - ì‹¤ì œ í¬ë¡¤ë§ ì‹¤í–‰ í›„ ê²°ê³¼ ë°˜í™˜ (ê°„ë‹¨ ë™ê¸°)"""
    logger.info(f"Crawl request: {crawl_request.infomax_code} from {request.client.host}")
    try:
        # í¬ë¡¤ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        crawler = LogoCrawler()
        ok = await crawler.crawl_logo(crawl_request.infomax_code, crawl_request.ticker, crawl_request.api_domain)
        return {
            "status": "success" if ok else "failed",
            "infomax_code": crawl_request.infomax_code,
            "ticker": crawl_request.ticker,
            "api_domain": crawl_request.api_domain
        }
    except Exception as e:
        logger.error(f"Crawl failed for {crawl_request.infomax_code}: {e}")
        raise HTTPException(status_code=500, detail=str(e))


class TickerInfo(BaseModel):
    infomax_code: str
    ticker: str
    api_domain: Optional[str] = None

class CrawlBatchRequest(BaseModel):
    tickers: List[TickerInfo]
    job_id: Optional[str] = None

@app.post("/api/v1/crawl/batch")
async def crawl_batch_logos(request: CrawlBatchRequest):
    """ë°°ì¹˜ ë¡œê³  í¬ë¡¤ë§"""
    try:
        tickers_data = [{"infomax_code": t.infomax_code, "ticker": t.ticker, "api_domain": t.api_domain} for t in request.tickers]
        
        # ì¿¼í„° ì²´í¬ (logo.dev ì‚¬ìš© ì˜ˆìƒëŸ‰)
        logo_dev_count = sum(1 for t in tickers_data if t.get('api_domain') == 'logo_dev')
        if logo_dev_count > 0:
            if not logo_dev_quota.check_and_consume_quota(logo_dev_count):
                print(f"âš ï¸ logo.dev ì¿¼í„° ë¶€ì¡±ìœ¼ë¡œ {logo_dev_count}ê±´ ìŠ¤í‚µ")
                # logo.dev í•­ëª© ì œê±°í•˜ê³  ë‹¤ë¥¸ ì†ŒìŠ¤ë§Œ ì²˜ë¦¬
                tickers_data = [t for t in tickers_data if t.get('api_domain') != 'logo_dev']
        
        if not tickers_data:
            return {"status": "no_quota", "message": "No items available after quota check"}
        
        # result_job_id = await crawler.crawl_batch(tickers_data, request.job_id)
        result_job_id = "test_job_id"  # ì„ì‹œë¡œ ë¹„í™œì„±í™”
        return {
            "status": "started", 
            "job_id": result_job_id, 
            "message": f"Batch crawling started for {len(tickers_data)} items",
            "quota_skipped": logo_dev_count if logo_dev_count > 0 and not logo_dev_quota.check_and_consume_quota(0) else 0
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/crawl/missing")
async def crawl_missing_logos(
    limit: int = 100,
    fs_exchange: Optional[str] = None,
    country: Optional[str] = None,
    is_active: Optional[bool] = None,
    prefix: Optional[str] = None
):
    """ë¡œê³ ê°€ ì—†ëŠ” ì¢…ëª©ë“¤ í¬ë¡¤ë§ - ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì """
    try:
        # ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë¯¸ë³´ìœ  ì¢…ëª© ìˆ˜ì§‘
        missing_items = await collect_missing_logos_streaming(
            limit=limit,
            fs_exchange=fs_exchange,
            country=country,
            is_active=is_active,
            prefix=prefix
        )
        
        if not missing_items:
            return {"status": "no_missing", "message": "No missing logos found with given filters"}
        
        print(f"ğŸ” ë¯¸ë³´ìœ  ì¢…ëª© {len(missing_items)}ê°œ ë°œê²¬")
        
        # í¬ë¡¤ë§í•  ë°ì´í„° ì¤€ë¹„
        tickers = []
        for item in missing_items:
            infomax_code = item['infomax_code']
            crawling_ticker = item.get('crawling_ticker', infomax_code)
            api_domain = item.get('api_domain', 'tradingview')
            
            tickers.append({
                "infomax_code": infomax_code,
                "ticker": crawling_ticker,
                "api_domain": api_domain
            })
        
        # ì¿¼í„° ì²´í¬ (logo.dev ì‚¬ìš© ì˜ˆìƒëŸ‰)
        logo_dev_count = sum(1 for t in tickers if t.get('api_domain') == 'logo_dev')
        if logo_dev_count > 0:
            if not logo_dev_quota.check_and_consume_quota(logo_dev_count):
                print(f"âš ï¸ logo.dev ì¿¼í„° ë¶€ì¡±ìœ¼ë¡œ {logo_dev_count}ê±´ ìŠ¤í‚µ")
                # logo.dev í•­ëª© ì œê±°í•˜ê³  ë‹¤ë¥¸ ì†ŒìŠ¤ë§Œ ì²˜ë¦¬
                tickers = [t for t in tickers if t.get('api_domain') != 'logo_dev']
        
        if not tickers:
            return {"status": "no_quota", "message": "No items available after quota check"}
        
        # ë°°ì¹˜ í¬ë¡¤ë§ ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…ìœ¼ë¡œ ì¦‰ì‹œ ë°˜í™˜)
        job_id = f"missing_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # ì§„í–‰ìƒí™© íŒŒì¼ ìƒì„±
        progress_data = {
            "job_id": job_id,
            "status": "running",
            "created_at": datetime.now().isoformat(),
            "total_items": len(tickers),
            "processed_items": 0,
            "successful_items": 0,
            "failed_items": 0,
            "items": []
        }
        
        # ì§„í–‰ìƒí™© íŒŒì¼ ì €ì¥
        progress_file = PROGRESS_DIR / f"{job_id}.json"
        with open(progress_file, 'w', encoding='utf-8') as f:
            json.dump(progress_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ” í¬ë¡¤ë§ ì‘ì—… ì‹œì‘: {job_id}")
        print(f"ğŸ“Š í¬ë¡¤ë§ ëŒ€ìƒ: {len(tickers)}ê°œ ì¢…ëª©")
        
        # ì‹¤ì œ í¬ë¡¤ë§ ì‘ì—… ìˆ˜í–‰ (ë°±ê·¸ë¼ìš´ë“œ)
        import asyncio
        import threading
        
        def run_crawl():
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            loop.run_until_complete(execute_crawl_batch(tickers, job_id))
            loop.close()
        
        thread = threading.Thread(target=run_crawl, daemon=True)
        thread.start()

        return {
            "status": "started",
            "job_id": job_id,
            "message": f"Missing logos crawling started for {len(tickers)} items",
            "filters_applied": {
                "fs_exchange": fs_exchange,
                "country": country,
                "is_active": is_active,
                "prefix": prefix
            },
            "quota_skipped": logo_dev_count if logo_dev_count > 0 and not logo_dev_quota.check_and_consume_quota(0) else 0
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

async def collect_missing_logos_streaming(
    limit: int = 100,
    fs_exchange: Optional[str] = None,
    country: Optional[str] = None,
    is_active: Optional[bool] = None,
    prefix: Optional[str] = None
) -> List[Dict]:
    """ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë¯¸ë³´ìœ  ë¡œê³  ìˆ˜ì§‘ - ë©”ëª¨ë¦¬ íš¨ìœ¨ì """
    collected = []
    page = 1
    size = 1000  # í•œ ë²ˆì— ê°€ì ¸ì˜¬ ìµœëŒ€ ìˆ˜
    
    # í•„í„° ì¡°ê±´ ì¤€ë¹„
    filters = {
        "fs_exchange": fs_exchange,
        "country": country,
        "is_active": is_active,
        "prefix": prefix
    }
    
    while len(collected) < limit:
        print(f"ğŸ” í˜ì´ì§€ {page} ì¡°íšŒ ì¤‘... (í˜„ì¬ ìˆ˜ì§‘: {len(collected)}/{limit})")
        
        # 1. prefixê°€ ìˆìœ¼ë©´ searchë¡œ ë¨¼ì € í•„í„°ë§
        if prefix:
            print(f"   prefix '{prefix}'ë¡œ ê²€ìƒ‰...")
            response = existing_api.query_table("raw_data", "logo_master", {
                "search": prefix,
                "search_column": "infomax_code",
                "page": page,
                "size": size
            })
        else:
            # 2. ëª¨ë“  ë°ì´í„°ë¥¼ í˜ì´ì§•ìœ¼ë¡œ ìˆ˜ì§‘
            print(f"   ì „ì²´ ë°ì´í„° ì¡°íšŒ...")
            response = existing_api.query_table("raw_data", "logo_master", {
                "page": page,
                "size": size
            })
        
        if not response or not response.get('data'):
            print(f"   âŒ ì‘ë‹µ ì—†ìŒ ë˜ëŠ” ë°ì´í„° ì—†ìŒ")
            break
        
        print(f"   ğŸ“Š í˜ì´ì§€ {page}ì—ì„œ {len(response['data'])}ê°œ í•­ëª© ì¡°íšŒ")
        
        # 3. ê°€ì ¸ì˜¨ ë°ì´í„°ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ í•„í„°ë§
        page_missing_count = 0
        for item in response['data']:
            if len(collected) >= limit:
                break
                
            # ëª¨ë“  í•­ëª©ì„ í¬ë¡¤ë§ ëŒ€ìƒìœ¼ë¡œ ê°„ì£¼ (ì¤‘ë³µ ì²´í¬ëŠ” ë‚˜ì¤‘ì— êµ¬í˜„)
            # ì¶”ê°€ í•„í„° ì¡°ê±´ í™•ì¸
            if should_include_item(item, filters):
                collected.append(item)
                page_missing_count += 1
                print(f"      âœ… ìˆ˜ì§‘: {item.get('infomax_code')}")
        
        print(f"   ğŸ“Š í˜ì´ì§€ {page}ì—ì„œ {page_missing_count}ê°œ ë¯¸ë³´ìœ  í•­ëª© ìˆ˜ì§‘")
        
        # 4. ë§ˆì§€ë§‰ í˜ì´ì§€ì¸ì§€ í™•ì¸
        if page >= response.get('total_pages', 1):
            print(f"   ğŸ“„ ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬")
            break
            
        page += 1
    
    return collected

def should_include_item(item: Dict, filters: Dict) -> bool:
    """ì•„ì´í…œì´ í•„í„° ì¡°ê±´ì— ë§ëŠ”ì§€ í™•ì¸"""
    if filters.get('fs_exchange') and item.get('fs_exchange') != filters['fs_exchange']:
        return False
    
    if filters.get('country') and item.get('country') != filters['country']:
        return False
    
    if filters.get('is_active') is not None and item.get('is_active') != filters['is_active']:
        return False
    
    # prefixëŠ” ì´ë¯¸ APIì—ì„œ í•„í„°ë§ë˜ì—ˆìœ¼ë¯€ë¡œ ì¶”ê°€ í™•ì¸ ë¶ˆí•„ìš”
    return True

async def is_logo_missing(infomax_code: str) -> bool:
    """í•´ë‹¹ infomax_codeì˜ ë¡œê³ ê°€ ì‹¤ì œë¡œ ì—†ëŠ”ì§€ í™•ì¸"""
    try:
        # 1. logo_hash ì¡°íšŒ
        logo_hash = get_logo_hash_from_master(infomax_code)
        
        # 2. logos í…Œì´ë¸”ì—ì„œ í™•ì¸
        logos_response = existing_api.query_table("raw_data", "logos", {
            "search_column": "logo_hash",
            "search": logo_hash,
            "is_deleted": False,
            "limit": 1
        })
        
        if not logos_response or not logos_response.get('data'):
            return True  # ë¡œê³  ì—†ìŒ
        
        logo_id = logos_response['data'][0]['logo_id']
        
        # 3. logo_files í…Œì´ë¸”ì—ì„œ ì‹¤ì œ íŒŒì¼ í™•ì¸
        files_response = existing_api.query_table("raw_data", "logo_files", {
            "page": 1,
            "size": 100
        })
        
        if not files_response or not files_response.get('data'):
            return True  # íŒŒì¼ ì—†ìŒ
        
        # í•´ë‹¹ logo_idì˜ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
        files = files_response['data']
        for f in files:
            if f.get('logo_id') == logo_id and f.get('minio_object_key'):
                # MinIOì—ì„œ ì‹¤ì œ íŒŒì¼ ì¡´ì¬ í™•ì¸
                try:
                    minio_client.stat_object(MINIO_BUCKET, f['minio_object_key'])
                    return False  # ë¡œê³  ìˆìŒ
                except:
                    continue  # íŒŒì¼ ì—†ìŒ, ê³„ì† í™•ì¸
        
        return True  # ë¡œê³  ì—†ìŒ
        
    except Exception as e:
        print(f"âš ï¸ ë¡œê³  ì¡´ì¬ í™•ì¸ ì˜¤ë¥˜: {infomax_code} - {e}")
        return True  # ì˜¤ë¥˜ ì‹œ í¬ë¡¤ë§ ëŒ€ìƒìœ¼ë¡œ ê°„ì£¼

async def execute_crawl_batch(tickers: List[Dict], job_id: str):
    """ì‹¤ì œ í¬ë¡¤ë§ ë°°ì¹˜ ì‹¤í–‰"""
    progress_file = PROGRESS_DIR / f"{job_id}.json"
    
    try:
        for i, ticker in enumerate(tickers):
            print(f"   {i+1}. {ticker['infomax_code']} ({ticker['ticker']}) - í¬ë¡¤ë§ ì‹œì‘")
            
            # ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸
            await update_progress(progress_file, {
                "processed_items": i + 1,
                "current_item": ticker['infomax_code']
            })
            
            # ì‹¤ì œ í¬ë¡¤ë§ ì‹œë®¬ë ˆì´ì…˜ (LogoCrawlerê°€ ì—†ìœ¼ë¯€ë¡œ)
            success = await simulate_crawl_single(ticker)
            
            if success:
                print(f"      âœ… ì„±ê³µ: {ticker['infomax_code']}")
                await update_progress(progress_file, {
                    "successful_items": i + 1
                })
            else:
                print(f"      âŒ ì‹¤íŒ¨: {ticker['infomax_code']}")
                await update_progress(progress_file, {
                    "failed_items": i + 1
                })
            
            # ì§„í–‰ìƒí™©ì— ì•„ì´í…œ ì •ë³´ ì¶”ê°€
            item_info = {
                "infomax_code": ticker['infomax_code'],
                "ticker": ticker['ticker'],
                "status": "success" if success else "failed",
                "processed_at": datetime.now().isoformat()
            }
            
            # ê¸°ì¡´ ì§„í–‰ìƒí™© ì½ê¸°
            with open(progress_file, 'r', encoding='utf-8') as f:
                progress_data = json.load(f)
            
            if "items" not in progress_data:
                progress_data["items"] = []
            progress_data["items"].append(item_info)
            
            # íŒŒì¼ ì €ì¥
            with open(progress_file, 'w', encoding='utf-8') as f:
                json.dump(progress_data, f, ensure_ascii=False, indent=2)
            
            # í¬ë¡¤ë§ ê°„ê²© (1ì´ˆ)
            await asyncio.sleep(1)
        
        # ì‘ì—… ì™„ë£Œ
        await update_progress(progress_file, {
            "status": "completed",
            "completed_at": datetime.now().isoformat()
        })
        
        print(f"ğŸ‰ í¬ë¡¤ë§ ì‘ì—… ì™„ë£Œ: {job_id}")
        
    except Exception as e:
        print(f"âŒ í¬ë¡¤ë§ ì‘ì—… ì˜¤ë¥˜: {job_id} - {e}")
        await update_progress(progress_file, {
            "status": "failed",
            "error": str(e),
            "failed_at": datetime.now().isoformat()
        })

async def simulate_crawl_single(ticker: Dict) -> bool:
    """ë‹¨ì¼ í¬ë¡¤ë§ ì‹œë®¬ë ˆì´ì…˜"""
    try:
        if LogoCrawler is None:
            print("      âŒ LogoCrawler ë¯¸ë¡œë”©: playwright í™˜ê²½ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return False

        print(f"      ğŸš€ ì‹¤ì œ í¬ë¡¤ë§ ì‹œì‘: {ticker['infomax_code']} ({ticker['ticker']})")
        crawler = LogoCrawler()
        # api_domainì€ í™˜ê²½ë³€ìˆ˜ì—ì„œ ì½ë„ë¡ ì„¤ê³„ë˜ì—ˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ None ì „ë‹¬
        ok = await crawler.crawl_logo(ticker['infomax_code'], ticker['ticker'], None)
        print(f"      âœ… í¬ë¡¤ë§ ê²°ê³¼: {'ì„±ê³µ' if ok else 'ì‹¤íŒ¨'} - {ticker['infomax_code']}")
        return bool(ok)
     
    except Exception as e:
        print(f"      âŒ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
        return False

async def update_progress(progress_file: Path, updates: Dict):
    """ì§„í–‰ìƒí™© íŒŒì¼ ì—…ë°ì´íŠ¸"""
    try:
        # ê¸°ì¡´ ì§„í–‰ìƒí™© ì½ê¸°
        with open(progress_file, 'r', encoding='utf-8') as f:
            progress_data = json.load(f)
        
        # ì—…ë°ì´íŠ¸ ì ìš©
        for key, value in updates.items():
            if key == "items":
                # itemsëŠ” ì¶”ê°€ (append)
                if "items" not in progress_data:
                    progress_data["items"] = []
                if isinstance(value, list):
                    progress_data["items"].extend(value)
                else:
                    progress_data["items"].append(value)
            else:
                progress_data[key] = value
        
        # íŒŒì¼ ì €ì¥
        with open(progress_file, 'w', encoding='utf-8') as f:
            json.dump(progress_data, f, ensure_ascii=False, indent=2)
            
    except Exception as e:
        print(f"âš ï¸ ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

@app.get("/api/v1/quota/status")
async def get_quota_status():
    """API ì¿¼í„° ìƒíƒœ ì¡°íšŒ"""
    try:
        today = date.today()
        
        # logo.dev ì¿¼í„° ìƒíƒœ
        logo_dev_usage = logo_dev_quota._get_current_usage(today)
        logo_dev_remaining = max(0, LOGO_DEV_DAILY_LIMIT - logo_dev_usage)
        
        return {
            "date_utc": today.isoformat(),
            "logo_dev": {
                "used": logo_dev_usage,
                "limit": LOGO_DEV_DAILY_LIMIT,
                "remaining": logo_dev_remaining,
                "percentage": round((logo_dev_usage / LOGO_DEV_DAILY_LIMIT) * 100, 2)
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ë¡œê³  ê´€ë¦¬ API
@app.post("/api/v1/logos/upload")
async def upload_logo(
    infomax_code: str = Form(...),
    file: UploadFile = File(...),
    format: str = Form("png"),
    size: int = Form(256),
    data_source: str = Form("manual")
):
    """ì‹ ê·œ ë¡œê³  ì—…ë¡œë“œ"""
    try:
        # 1. íŒŒì¼ ê²€ì¦
        if not validate_image_file(file):
            raise HTTPException(status_code=400, detail="Invalid file type. Only PNG, JPEG, WebP, SVG are supported")
        
        # 2. infomax_code ê²€ì¦ (ê¸°ì¡´ master ë°ì´í„°ì— ìˆëŠ”ì§€ í™•ì¸)
        master_response = existing_api.query_table("raw_data", "logo_master", {
            "infomax_code": infomax_code,
            "limit": 1
        })
        
        if not master_response or not master_response.get('data'):
            raise HTTPException(status_code=404, detail=f"infomax_code '{infomax_code}' not found in master data")
        
        # 3. ì´ë¯¸ì§€ ë°ì´í„° ì½ê¸°
        image_data = await file.read()
        
        # 4. ì´ë¯¸ì§€ ì²˜ë¦¬
        processed_image = process_uploaded_image(image_data, target_size=size, target_format=format)
        
        # 5. logo_hash ì¡°íšŒ (DBì—ì„œ)
        logo_hash = get_logo_hash_from_master(infomax_code)
        
        # 6. MinIOì— ì—…ë¡œë“œ (logo_hash ì‚¬ìš©)
        minio_key = f"{logo_hash}_{size}.{format.lower()}"
        minio_client.put_object(
            MINIO_BUCKET, 
            minio_key, 
            io.BytesIO(processed_image),
            length=len(processed_image),
            content_type=f"image/{format.lower()}"
        )
        
        # 7. DBì— ì €ì¥
        success = save_logo_data(infomax_code, logo_hash, {
            "format": format.lower(),
            "source": data_source,
            "upload_type": "manual",
            "width": size,
            "height": size,
            "size": len(processed_image),
            "minio_key": minio_key,
            "is_original": True
        })
        
        if success:
            return {
                "status": "success", 
                "message": "Logo uploaded successfully",
                "data": {
                    "infomax_code": infomax_code,
                    "logo_hash": logo_hash,
                    "format": format.lower(),
                    "size": size,
                    "minio_key": minio_key
                }
            }
        else:
            raise HTTPException(status_code=500, detail="Failed to save logo data to database")
            
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Upload failed: {str(e)}")

@app.put("/api/v1/logos/{infomax_code}")
async def update_logo(
    infomax_code: str,
    file: UploadFile = File(...),
    format: str = Form("png"),
    size: int = Form(256)
):
    """ê¸°ì¡´ ë¡œê³  ìˆ˜ì •"""
    try:
        # 1. ê¸°ì¡´ ë¡œê³  ì¡°íšŒ
        master_response = existing_api.query_table("raw_data", "logo_master", {
            "infomax_code": infomax_code,
            "limit": 1
        })
        
        if not master_response or not master_response.get('data'):
            raise HTTPException(status_code=404, detail=f"infomax_code '{infomax_code}' not found in master data")
        
        # 2. íŒŒì¼ ê²€ì¦
        if not validate_image_file(file):
            raise HTTPException(status_code=400, detail="Invalid file type. Only PNG, JPEG, WebP, SVG are supported")
        
        # 3. ì´ë¯¸ì§€ ë°ì´í„° ì½ê¸° ë° ì²˜ë¦¬
        image_data = await file.read()
        processed_image = process_uploaded_image(image_data, target_size=size, target_format=format)
        
        # 4. logo_hash ì¡°íšŒ (DBì—ì„œ)
        logo_hash = get_logo_hash_from_master(infomax_code)
        
        # 5. ê¸°ì¡´ íŒŒì¼ ì‚­ì œ (MinIO)
        try:
            minio_client.remove_object(MINIO_BUCKET, f"{logo_hash}_{size}.{format.lower()}")
        except:
            pass  # íŒŒì¼ì´ ì—†ì–´ë„ ê³„ì† ì§„í–‰
        
        # 6. ìƒˆ íŒŒì¼ ì—…ë¡œë“œ (logo_hash ì‚¬ìš©)
        minio_key = f"{logo_hash}_{size}.{format.lower()}"
        minio_client.put_object(
            MINIO_BUCKET, 
            minio_key, 
            io.BytesIO(processed_image),
            length=len(processed_image),
            content_type=f"image/{format.lower()}"
        )
        
        # 7. DBì— ì €ì¥ (ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸)
        success = save_logo_data(infomax_code, logo_hash, {
            "format": format.lower(),
            "source": "manual",
            "upload_type": "manual",
            "width": size,
            "height": size,
            "size": len(processed_image),
            "minio_key": minio_key,
            "is_original": True
        })
        
        if success:
            return {
                "status": "success", 
                "message": "Logo updated successfully",
                "data": {
                    "infomax_code": infomax_code,
                    "logo_hash": logo_hash,
                    "format": format.lower(),
                    "size": size,
                    "minio_key": minio_key
                }
            }
        else:
            raise HTTPException(status_code=500, detail="Failed to update logo data in database")
            
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Update failed: {str(e)}")

@app.delete("/api/v1/logos/{infomax_code}")
async def delete_logo(infomax_code: str):
    """ë¡œê³  ì‚­ì œ (ë…¼ë¦¬ì  ì‚­ì œ)"""
    try:
        # 1. ë¨¼ì € master ë°ì´í„°ì—ì„œ infomax_codeë¡œ ì¡°íšŒí•˜ì—¬ ì‹¤ì œ logo_hash í™•ì¸
        master_response = existing_api.query_table("raw_data", "logo_master", {
            "infomax_code": infomax_code,
            "limit": 1
        })
        
        if not master_response or 'data' not in master_response or not master_response['data']:
            raise HTTPException(status_code=404, detail="Ticker not found in master data")
        
        master_data = master_response['data'][0]
        logo_hash = master_data['logo_hash']
        
        # 2. logos í…Œì´ë¸”ì—ì„œ í•´ë‹¹ logo_hashë¡œ ì‚­ì œë˜ì§€ ì•Šì€ ë ˆì½”ë“œ í™•ì¸
        logo_response = existing_api.query_table("raw_data", "logos", {
            "logo_hash": logo_hash,
            "is_deleted": False,
            "limit": 1
        })
        
        if not logo_response or 'data' not in logo_response or not logo_response['data']:
            raise HTTPException(status_code=404, detail="Logo not found")
        
        # 2. logos í…Œì´ë¸”ì—ì„œ is_deleted = trueë¡œ ì—…ë°ì´íŠ¸
        logo_data = {
            "data": {
                "logo_hash": logo_hash,
                "is_deleted": True,
                "deleted_by": "api_user"
            },
            "conflict_columns": ["logo_hash"]
        }
        
        result = existing_api.upsert_data("raw_data", "logos", logo_data)
        
        if result:
            return {
                "status": "success", 
                "message": "Logo deleted successfully",
                "data": {
                    "infomax_code": infomax_code,
                    "logo_hash": logo_hash,
                    "deleted_at": datetime.now().isoformat()
                }
            }
        else:
            raise HTTPException(status_code=500, detail="Failed to delete logo from database")
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Delete failed: {str(e)}")

@app.get("/api/v1/debug/test-logo")
async def debug_test_logo(infomax_code: str = "DEBUG:TEST"):
    """ë””ë²„ê·¸ìš© ë¡œê³  ìƒì„± í…ŒìŠ¤íŠ¸"""
    try:
        ticker = {
            "infomax_code": infomax_code,
            "ticker": "DEBUG-TEST"
        }
        
        result = await create_test_logo_file(ticker)
        return {
            "success": result,
            "infomax_code": infomax_code,
            "message": "í…ŒìŠ¤íŠ¸ ë¡œê³  ìƒì„± ì™„ë£Œ" if result else "í…ŒìŠ¤íŠ¸ ë¡œê³  ìƒì„± ì‹¤íŒ¨"
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "infomax_code": infomax_code
        }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "api_server:app",
        host="0.0.0.0",
        port=8005,
        reload=True,
        log_level="info"
    )
