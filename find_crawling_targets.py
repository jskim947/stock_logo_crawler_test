#!/usr/bin/env python3
"""
í¬ë¡¤ë§ ëŒ€ìƒ ì¢…ëª© ì°¾ê¸°
- ë‹¤ì–‘í•œ ì¡°ê±´ìœ¼ë¡œ ë¯¸ë³´ìœ  ë¡œê³  ì¡°íšŒ
- í¬ë¡¤ë§ ê°€ëŠ¥í•œ ì¢…ëª© í™•ì¸
"""

import requests
import json

def find_crawling_targets():
    """í¬ë¡¤ë§ ëŒ€ìƒ ì¢…ëª© ì°¾ê¸°"""
    
    base_url = "http://localhost:8005"
    
    print("ğŸ” í¬ë¡¤ë§ ëŒ€ìƒ ì¢…ëª© ì°¾ê¸°")
    print("=" * 50)
    
    # ë‹¤ì–‘í•œ ì¡°ê±´ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
    test_conditions = [
        {"prefix": "NAS:Q", "limit": 5},
        {"prefix": "NYSE", "limit": 5},
        {"prefix": "AMX", "limit": 5},
        {"has_logo": False, "limit": 10},
        {"limit": 10}  # ì „ì²´
    ]
    
    for i, condition in enumerate(test_conditions, 1):
        print(f"\n{i}ï¸âƒ£ ì¡°ê±´ í…ŒìŠ¤íŠ¸: {condition}")
        
        try:
            response = requests.get(f"{base_url}/api/v1/crawl/missing", 
                                  params=condition, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                missing_logos = data.get('results', [])
                print(f"   ğŸ“Š ë¯¸ë³´ìœ  ë¡œê³ : {len(missing_logos)}ê°œ")
                
                if missing_logos:
                    print("   ğŸ“‹ ìƒ˜í”Œ ì¢…ëª©:")
                    for j, item in enumerate(missing_logos[:3]):
                        print(f"      {j+1}. {item.get('infomax_code')} - {item.get('english_name', 'N/A')[:50]}...")
                        print(f"         í‹°ì»¤: {item.get('ticker')}, ê±°ë˜ì†Œ: {item.get('fs_exchange')}")
                    
                    # ì²« ë²ˆì§¸ ì¢…ëª©ìœ¼ë¡œ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸
                    if i == 1:  # ì²« ë²ˆì§¸ ì¡°ê±´ì—ì„œë§Œ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸
                        test_item = missing_logos[0]
                        test_infomax_code = test_item.get('infomax_code')
                        test_ticker = test_item.get('ticker')
                        
                        if test_infomax_code and test_ticker:
                            print(f"\n   ğŸ¯ '{test_infomax_code}' í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸...")
                            test_single_crawling(base_url, test_infomax_code, test_ticker)
                else:
                    print("   â„¹ï¸ ë¯¸ë³´ìœ  ë¡œê³  ì—†ìŒ")
            else:
                print(f"   âŒ ì¡°íšŒ ì‹¤íŒ¨: {response.status_code}")
        except Exception as e:
            print(f"   âŒ ì˜¤ë¥˜: {e}")

def test_single_crawling(base_url: str, infomax_code: str, ticker: str):
    """ë‹¨ì¼ ì¢…ëª© í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸"""
    
    print(f"   3ï¸âƒ£ '{infomax_code}' í¬ë¡¤ë§ ì‹¤í–‰...")
    
    # í¬ë¡¤ë§ ìš”ì²­
    crawl_data = {
        "infomax_code": infomax_code,
        "ticker": ticker,
        "api_domain": None
    }
    
    try:
        response = requests.post(f"{base_url}/api/v1/crawl/single", 
                               json=crawl_data, timeout=60)
        
        if response.status_code == 200:
            result = response.json()
            print(f"      âœ… í¬ë¡¤ë§ ì™„ë£Œ: {result.get('status')}")
            print(f"      ğŸ“Š ê²°ê³¼: {result}")
            
            # í¬ë¡¤ë§ í›„ ì €ì¥ í™•ì¸
            print(f"\n   4ï¸âƒ£ í¬ë¡¤ë§ ê²°ê³¼ ì €ì¥ í™•ì¸...")
            check_crawling_results(base_url, infomax_code)
        else:
            print(f"      âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: {response.status_code}")
            print(f"      ğŸ“ ì‘ë‹µ: {response.text}")
    except Exception as e:
        print(f"      âŒ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")

def check_crawling_results(base_url: str, infomax_code: str):
    """í¬ë¡¤ë§ ê²°ê³¼ í™•ì¸"""
    
    # 1. ë¡œê³  ë©”íƒ€ë°ì´í„° í™•ì¸
    print(f"      ğŸ“Š ë¡œê³  ë©”íƒ€ë°ì´í„° í™•ì¸...")
    try:
        response = requests.get(f"{base_url}/api/v1/logo-info", 
                              params={"infomax_code": infomax_code}, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            print(f"         âœ… ë©”íƒ€ë°ì´í„° ì¡°íšŒ ì„±ê³µ")
            print(f"         ğŸ“Š ë¡œê³  ì¡´ì¬: {data.get('logo_exists')}")
            print(f"         ğŸ“Š ë¡œê³  í•´ì‹œ: {data.get('logo_hash')}")
            
            file_info = data.get('file_info', {})
            if file_info:
                print(f"         ğŸ“Š íŒŒì¼ í˜•ì‹: {file_info.get('file_format')}")
                print(f"         ğŸ“Š íŒŒì¼ í¬ê¸°: {file_info.get('file_size')} bytes")
                print(f"         ğŸ“Š MinIO í‚¤: {file_info.get('minio_object_key')}")
                print(f"         ğŸ“Š ë°ì´í„° ì†ŒìŠ¤: {file_info.get('data_source')}")
                
                # 2. MinIO íŒŒì¼ í™•ì¸
                minio_key = file_info.get('minio_object_key')
                if minio_key:
                    print(f"\n      ğŸ“Š MinIO íŒŒì¼ í™•ì¸...")
                    check_minio_file(minio_key)
                
                # 3. ë¡œê³  ì´ë¯¸ì§€ ì¡°íšŒ í…ŒìŠ¤íŠ¸
                print(f"\n      ğŸ“Š ë¡œê³  ì´ë¯¸ì§€ ì¡°íšŒ í…ŒìŠ¤íŠ¸...")
                test_logo_retrieval(base_url, infomax_code)
            else:
                print(f"         âŒ íŒŒì¼ ì •ë³´ ì—†ìŒ")
        else:
            print(f"         âŒ ë©”íƒ€ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {response.status_code}")
    except Exception as e:
        print(f"         âŒ ì˜¤ë¥˜: {e}")

def check_minio_file(minio_key: str):
    """MinIO íŒŒì¼ í™•ì¸"""
    try:
        from minio import Minio
        
        minio_client = Minio(
            'localhost:9000',
            access_key='minioadmin',
            secret_key='minioadmin123',
            secure=False
        )
        
        bucket_name = 'logos'
        
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        try:
            stat = minio_client.stat_object(bucket_name, minio_key)
            print(f"            âœ… MinIO íŒŒì¼ ì¡´ì¬: {minio_key}")
            print(f"            ğŸ“Š í¬ê¸°: {stat.size} bytes")
            print(f"            ğŸ“Š ìˆ˜ì •ì¼: {stat.last_modified}")
        except Exception as e:
            print(f"            âŒ MinIO íŒŒì¼ ì—†ìŒ: {e}")
    except Exception as e:
        print(f"            âŒ MinIO ì—°ê²° ì‹¤íŒ¨: {e}")

def test_logo_retrieval(base_url: str, infomax_code: str):
    """ë¡œê³  ì´ë¯¸ì§€ ì¡°íšŒ í…ŒìŠ¤íŠ¸"""
    
    test_sizes = [240, 300]
    
    for size in test_sizes:
        try:
            print(f"         {size}px ì¡°íšŒ...")
            response = requests.get(f"{base_url}/api/v1/logos/{infomax_code}", 
                                  params={"format": "png", "size": size}, timeout=10)
            
            if response.status_code == 200:
                content_type = response.headers.get('content-type', '')
                content_length = len(response.content)
                print(f"            âœ… ì„±ê³µ: {content_type}, {content_length} bytes")
            else:
                print(f"            âŒ ì‹¤íŒ¨: {response.status_code}")
        except Exception as e:
            print(f"            âŒ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    find_crawling_targets()
    
    print("\n" + "=" * 50)
    print("ğŸ¯ í¬ë¡¤ë§ ëŒ€ìƒ ì¢…ëª© ì°¾ê¸° ì™„ë£Œ!")
    print("=" * 50)
