"""
ë¡œê³  í¬ë¡¤ë§ ëª¨ë“ˆ
ì›¹ì‚¬ì´íŠ¸ì™€ logo.devì—ì„œ ë¡œê³ ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µ
"""

import asyncio
import aiohttp
import requests
import hashlib
import os
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from io import BytesIO
import json

from playwright.async_api import async_playwright
from fake_useragent import UserAgent
from PIL import Image
from minio import Minio
import logging

logger = logging.getLogger(__name__)

class DateTimeEncoder(json.JSONEncoder):
    """datetime ê°ì²´ë¥¼ JSONìœ¼ë¡œ ì§ë ¬í™”í•˜ëŠ” ì»¤ìŠ¤í…€ ì¸ì½”ë”"""
    def default(self, obj):
        if isinstance(obj, datetime):
            return obj.isoformat()
        return super().default(obj)

class LogoCrawler:
    """ë¡œê³  í¬ë¡¤ë§ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.ua = UserAgent()
        self.minio_client = Minio(
            os.getenv('MINIO_ENDPOINT', 'minio:9000'),
            access_key=os.getenv('MINIO_ACCESS_KEY', 'minioadmin'),
            secret_key=os.getenv('MINIO_SECRET_KEY', 'minioadmin123'),
            secure=False
        )
        self.bucket = os.getenv('MINIO_BUCKET', 'logos')
        self.existing_api_base = os.getenv('EXISTING_API_BASE', 'http://10.150.2.150:8004')
        self.logo_dev_token = os.getenv('LOGO_DEV_TOKEN')
        
        # existing_api ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        from api_server import existing_api
        self.existing_api = existing_api
        
    async def crawl_website(self, infomax_code: str, ticker: str) -> Optional[bytes]:
        """ì›¹ì‚¬ì´íŠ¸ì—ì„œ ë¡œê³  í¬ë¡¤ë§ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
        max_retries = 3
        base_timeout = 10000  # 10ì´ˆ
        
        for attempt in range(max_retries):
            try:
                logger.info(f"ì›¹ì‚¬ì´íŠ¸ í¬ë¡¤ë§ ì‹œë„ {attempt + 1}/{max_retries}: {infomax_code}")
                
                # ì‹œë„ë§ˆë‹¤ íƒ€ì„ì•„ì›ƒ ì¦ê°€
                timeout = base_timeout + (attempt * 5000)  # 10ì´ˆ, 15ì´ˆ, 20ì´ˆ
                
                async with async_playwright() as p:
                    browser = await p.chromium.launch(headless=True)
                    context = await browser.new_context(
                        viewport={'width': 1920, 'height': 1080},
                        user_agent=self.ua.random
                    )
                    # í˜ì´ì§€ íƒ€ì„ì•„ì›ƒ ì„¤ì •
                    context.set_default_timeout(timeout)
                    
                    page = await context.new_page()
                    
                    # ì›¹ì‚¬ì´íŠ¸ í˜ì´ì§€ë¡œ ì´ë™
                    base_url = os.getenv('WEBSITE_BASE_URL', 'https://example.com')
                    url = f"{base_url}/symbols/{ticker}/news"
                    print(f"ğŸ” ì›¹ì‚¬ì´íŠ¸ URL: {url} (íƒ€ì„ì•„ì›ƒ: {timeout}ms)")
                    await page.goto(url, timeout=timeout)
                    
                    # ë¡œê³  ì´ë¯¸ì§€ ì„ íƒì (ì—¬ëŸ¬ ê°€ëŠ¥ì„± ì‹œë„)
                    selectors = [
                        'img[data-testid="logo"]',
                        '.tv-symbol-header__logo img',
                        '.tv-symbol-header__logo svg',
                        '#js-category-content > div.js-symbol-page-header-root > div > div.symbolRow-NopKb87z > div > div.container-F4HZNWkx.logo-iJMmXWiA > img.logo-PsAlMQQF.xxxlarge-PsAlMQQF.large-F4HZNWkx.letter-PsAlMQQF',
                        'img[alt*="logo" i]',
                        'img[src*="logo" i]',
                        '.tv-symbol-header img',
                        'header img'
                    ]
                    
                    # XPath ì…€ë ‰í„° ì¶”ê°€ (img íƒœê·¸ë¥¼ ì°¾ì•„ì„œ srcì—ì„œ SVG URL ì¶”ì¶œ)
                    xpath_selectors = [
                        # ì›ë˜ XPathë“¤ (ë” ìœ ì—°í•˜ê²Œ ìˆ˜ì •)
                        '/html/body/div[2]/main/div[2]/div[1]/div/div[1]/div/div[1]/img[1]',
                        '/html/body/div[2]/main/div[2]/div[1]/div/div[1]/div/div[1]/img[2]',
                        '/html/body/div[2]/main/div[2]/div[1]/div/div[1]/div/div[1]/img[3]',
                        # ë” ìœ ì—°í•œ XPathë“¤
                        '//div[contains(@class, "symbolRow")]//img[1]',
                        '//div[contains(@class, "symbolRow")]//img[2]',
                        '//div[contains(@class, "symbolRow")]//img[3]',
                        '//div[contains(@class, "logo")]//img[1]',
                        '//div[contains(@class, "logo")]//img[2]',
                        '//div[contains(@class, "logo")]//img[3]',
                        # ì¼ë°˜ì ì¸ img íƒœê·¸ë“¤
                        '//img[contains(@class, "logo")]',
                        '//img[contains(@src, "svg")]'
                    ]
                    
                    # XPath ì…€ë ‰í„° ìš°ì„  ì‹œë„
                    for xpath in xpath_selectors:
                        try:
                            element = await page.wait_for_selector(f"xpath={xpath}", timeout=3000, state="attached")
                            if element:
                                # SVGì¸ ê²½ìš°
                                if 'svg' in xpath:
                                    svg_content = await element.inner_html()
                                    await browser.close()
                                    print(f"âœ… SVG í¬ë¡¤ë§ ì„±ê³µ (XPath): {infomax_code}")
                                    return svg_content.encode('utf-8')
                                # IMGì¸ ê²½ìš°
                                else:
                                    src = await element.get_attribute('src')
                                    print(f"ğŸ” XPath IMG src ë°œê²¬: {src}")
                                    if src:
                                        # êµ­ê¸° ì´ë¯¸ì§€ ì œì™¸ (country/ë¡œ ì‹œì‘í•˜ê³  .svgë¡œ ëë‚˜ëŠ” ê²½ìš°)
                                        if 'country/' in src and src.endswith('.svg'):
                                            print(f"ğŸ” êµ­ê¸° ì´ë¯¸ì§€ ì œì™¸: {src}")
                                            await browser.close()
                                            return None  # logo.devë¡œ í´ë°±
                                        
                                        # ìƒëŒ€ ê²½ë¡œì¸ ê²½ìš° ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
                                        if not src.startswith('http'):
                                            base_url = os.getenv('WEBSITE_BASE_URL', 'https://example.com')
                                            src = f"{base_url}{src}" if src.startswith('/') else f"{base_url}/{src}"
                                        
                                        print(f"ğŸ” ìµœì¢… URL: {src}")
                                        timeout_http = aiohttp.ClientTimeout(total=10)  # 10ì´ˆ íƒ€ì„ì•„ì›ƒ
                                        async with aiohttp.ClientSession(timeout=timeout_http) as session:
                                            async with session.get(src) as response:
                                                if response.status == 200:
                                                    data = await response.read()
                                                    await browser.close()
                                                    print(f"âœ… IMG í¬ë¡¤ë§ ì„±ê³µ (XPath): {infomax_code}, í¬ê¸°: {len(data)} bytes")
                                                    return data
                                                else:
                                                    print(f"ğŸ” HTTP ì‘ë‹µ ì‹¤íŒ¨: {response.status}")
                                    else:
                                        print(f"ğŸ” XPath IMG src ì—†ìŒ: {xpath}")
                                        continue
                        except Exception as e:
                            print(f"ğŸ” XPath ì…€ë ‰í„° ì‹¤íŒ¨: {xpath} - {e}")
                            continue
                    
                    # CSS ì…€ë ‰í„° ì‹œë„ (XPath ì‹¤íŒ¨ ì‹œ)
                    for selector in selectors:
                        try:
                            element = await page.wait_for_selector(selector, timeout=3000, state="attached")  # 3ì´ˆë¡œ ë‹¨ì¶•
                            if element:
                                # SVGì¸ ê²½ìš°
                                if 'svg' in selector:
                                    svg_content = await element.inner_html()
                                    await browser.close()
                                    print(f"âœ… SVG í¬ë¡¤ë§ ì„±ê³µ (CSS): {infomax_code}")
                                    return svg_content.encode('utf-8')
                                # IMGì¸ ê²½ìš°
                                else:
                                    src = await element.get_attribute('src')
                                    print(f"ğŸ” CSS IMG src ë°œê²¬: {src}")
                                    if src:
                                        # êµ­ê¸° ì´ë¯¸ì§€ ì œì™¸ (country/ë¡œ ì‹œì‘í•˜ê³  .svgë¡œ ëë‚˜ëŠ” ê²½ìš°)
                                        if 'country/' in src and src.endswith('.svg'):
                                            print(f"ğŸ” êµ­ê¸° ì´ë¯¸ì§€ ì œì™¸: {src}")
                                            await browser.close()
                                            return None  # logo.devë¡œ í´ë°±
                                        
                                        # ìƒëŒ€ ê²½ë¡œì¸ ê²½ìš° ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
                                        if not src.startswith('http'):
                                            base_url = os.getenv('WEBSITE_BASE_URL', 'https://example.com')
                                            src = f"{base_url}{src}" if src.startswith('/') else f"{base_url}/{src}"
                                        
                                        print(f"ğŸ” ìµœì¢… URL: {src}")
                                        timeout_http = aiohttp.ClientTimeout(total=10)  # 10ì´ˆ íƒ€ì„ì•„ì›ƒ
                                        async with aiohttp.ClientSession(timeout=timeout_http) as session:
                                            async with session.get(src) as response:
                                                if response.status == 200:
                                                    data = await response.read()
                                                    await browser.close()
                                                    print(f"âœ… IMG í¬ë¡¤ë§ ì„±ê³µ (CSS): {infomax_code}, í¬ê¸°: {len(data)} bytes")
                                                    return data
                                                else:
                                                    print(f"ğŸ” HTTP ì‘ë‹µ ì‹¤íŒ¨: {response.status}")
                        except Exception as e:
                            print(f"ğŸ” CSS ì…€ë ‰í„° ì‹¤íŒ¨: {selector} - {e}")
                            continue
                    
                    await browser.close()
                    print(f"âŒ ëª¨ë“  ì…€ë ‰í„° ì‹¤íŒ¨: {infomax_code}")
                    if attempt < max_retries - 1:
                        print(f"ğŸ”„ ì¬ì‹œë„ ì˜ˆì •: {infomax_code}")
                        continue
                    return None
                    
            except Exception as e:
                print(f"ì›¹ì‚¬ì´íŠ¸ í¬ë¡¤ë§ ì˜¤ë¥˜ ({infomax_code}, ì‹œë„ {attempt + 1}): {e}")
                if attempt < max_retries - 1:
                    print(f"ğŸ”„ ì¬ì‹œë„ ì˜ˆì •: {infomax_code}")
                    continue
                return None
        
        return None
    
    async def crawl_logo_dev(self, infomax_code: str, api_domain: str) -> Optional[bytes]:
        """logo.dev APIì—ì„œ ë¡œê³  í¬ë¡¤ë§"""
        print(f"ğŸ” logo.dev í¬ë¡¤ë§ ì‹œì‘: {infomax_code}, api_domain: {api_domain}")
        try:
            if not self.logo_dev_token:
                print("âŒ LOGO_DEV_TOKENì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                return None
            
            print(f"ğŸ” logo.dev í† í° í™•ì¸: {self.logo_dev_token[:10]}...")
            
            # API ì¿¼í„° í™•ì¸
            if not await self._check_quota('logo_dev'):
                print("logo.dev ì¼ì¼ ì¿¼í„° ì´ˆê³¼")
                return None
            
            url = f"https://img.logo.dev/{api_domain}?token={self.logo_dev_token}&format=png&size=300&fallback=404"
            print(f"ğŸ” logo.dev API URL: {url}")
            
            timeout = aiohttp.ClientTimeout(total=15)  # 15ì´ˆ íƒ€ì„ì•„ì›ƒ
            async with aiohttp.ClientSession(timeout=timeout) as session:
                print(f"ğŸ” logo.dev API í˜¸ì¶œ ì‹œì‘: {api_domain}")
                async with session.get(url) as response:
                    print(f"ğŸ” logo.dev API ì‘ë‹µ: {response.status}")
                    if response.status == 200:
                        data = await response.read()
                        print(f"âœ… logo.dev í¬ë¡¤ë§ ì„±ê³µ: {infomax_code}, í¬ê¸°: {len(data)} bytes")
                        # ì¿¼í„° ì‚¬ìš©ëŸ‰ ì—…ë°ì´íŠ¸
                        await self._update_quota('logo_dev')
                        return data
                    else:
                        print(f"âŒ logo.dev API ì˜¤ë¥˜: {response.status}")
                        return None
                        
        except Exception as e:
            print(f"logo.dev í¬ë¡¤ë§ ì˜¤ë¥˜ ({infomax_code}): {e}")
            return None
    
    async def _check_quota(self, provider: str) -> bool:
        """API ì¿¼í„° í™•ì¸"""
        try:
            # ê¸°ì¡´ APIë¥¼ í†µí•´ ì¿¼í„° í™•ì¸
            timeout = aiohttp.ClientTimeout(total=10)  # 10ì´ˆ íƒ€ì„ì•„ì›ƒ
            async with aiohttp.ClientSession(timeout=timeout) as session:
                url = f"{self.existing_api_base}/api/query/raw_data/ext_api_quota"
                params = {
                    "api_name": provider,
                    "quota_date": datetime.now().strftime('%Y-%m-%d'),
                    "limit": 1
                }
                async with session.get(url, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        print(f"ğŸ” ì¿¼í„° í™•ì¸ ì‘ë‹µ: {data}")
                        # í˜ì´ì§€ë„¤ì´ì…˜ëœ ì‘ë‹µ êµ¬ì¡° í™•ì¸
                        if 'data' in data and data['data'] and len(data['data']) > 0:
                            used_count = data['data'][0].get('used_count', 0)
                            max_count = data['data'][0].get('max_count', 5000)
                            print(f"ğŸ” ì¿¼í„° ì‚¬ìš©ëŸ‰: {used_count}/{max_count}")
                            return used_count < max_count
                        elif data and len(data) > 0:
                            used_count = data[0].get('used_count', 0)
                            max_count = data[0].get('max_count', 5000)
                            print(f"ğŸ” ì¿¼í„° ì‚¬ìš©ëŸ‰ (ì§ì ‘): {used_count}/{max_count}")
                            return used_count < max_count
            print(f"ğŸ” ì¿¼í„° í™•ì¸ ì‹¤íŒ¨, ê¸°ë³¸ê°’ True ë°˜í™˜")
            return True
        except:
            return True
    
    async def _update_quota(self, provider: str):
        """API ì¿¼í„° ì‚¬ìš©ëŸ‰ ì—…ë°ì´íŠ¸"""
        try:
            # ê¸°ì¡´ APIë¥¼ í†µí•´ ì¿¼í„° ì—…ë°ì´íŠ¸
            timeout = aiohttp.ClientTimeout(total=10)  # 10ì´ˆ íƒ€ì„ì•„ì›ƒ
            async with aiohttp.ClientSession(timeout=timeout) as session:
                url = f"{self.existing_api_base}/api/schemas/raw_data/tables/ext_api_quota/upsert"
                data = {
                    "api_name": provider,
                    "quota_date": datetime.now().strftime('%Y-%m-%d'),
                    "used_count": 1,
                    "max_count": 5000
                }
                async with session.post(url, json=data) as response:
                    pass  # ê²°ê³¼ëŠ” ë¬´ì‹œ
        except:
            pass
    
    def convert_image(self, image_data: bytes, infomax_code: str) -> Dict[str, bytes]:
        """ì´ë¯¸ì§€ë¥¼ ë‹¤ì–‘í•œ í¬ê¸°ë¡œ ë³€í™˜ (SVG â†’ PNG/WebP í¬í•¨)"""
        print(f"ğŸ” convert_image í•¨ìˆ˜ ì§„ì…: {infomax_code}")
        try:
            results = {}
            image = None
            
            # SVGì¸ ê²½ìš° PNG/WebPë¡œ ë³€í™˜
            print(f"ğŸ” ì´ë¯¸ì§€ ë°ì´í„° í™•ì¸: {infomax_code}, ì‹œì‘ ë°”ì´íŠ¸: {image_data[:50]}")
            if image_data.startswith(b'<svg') or image_data.startswith(b'<?xml'):
                print(f"ğŸ” SVG íŒŒì¼ ê°ì§€: {infomax_code}")
                
                # SVGë¥¼ PIL Imageë¡œ ë³€í™˜í•˜ê¸° ìœ„í•´ cairosvg ì‚¬ìš© ì‹œë„
                try:
                    import cairosvg
                    # SVGë¥¼ PNGë¡œ ë³€í™˜
                    png_data = cairosvg.svg2png(bytestring=image_data)
                    print(f"ğŸ” SVG â†’ PNG ë³€í™˜ ì™„ë£Œ: {infomax_code} ({len(png_data)} bytes)")
                    
                    # PNG ë°ì´í„°ë¥¼ PIL Imageë¡œ ì—´ê¸°
                    png_buffer = BytesIO(png_data)
                    image = Image.open(png_buffer)
                    print(f"âœ… SVG â†’ PNG â†’ PIL Image ë³€í™˜ ì„±ê³µ: {infomax_code}, í¬ê¸°: {image.size}")
                except ImportError:
                    print("âŒ cairosvgê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ. SVG ì›ë³¸ë§Œ ì €ì¥")
                    return {"original": image_data}
                except Exception as e:
                    print(f"âŒ SVG ë³€í™˜ ì‹¤íŒ¨: {e}")
                    print(f"ğŸ” PNG ë°ì´í„° í™•ì¸: {png_data[:50] if 'png_data' in locals() else 'None'}")
                    return {"original": image_data}
            else:
                # ì¼ë°˜ ì´ë¯¸ì§€ íŒŒì¼
                print(f"ğŸ” ì¼ë°˜ ì´ë¯¸ì§€ íŒŒì¼ ê°ì§€: {infomax_code}")
                image_buffer = BytesIO(image_data)
                image = Image.open(image_buffer)
            
            # imageê°€ Noneì´ë©´ ë³€í™˜ ì‹¤íŒ¨
            if image is None:
                print(f"âŒ ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨: {infomax_code}")
                return {"original": image_data}
            
            print(f"ğŸ” ì´ë¯¸ì§€ ë³€í™˜ ì‹œì‘: {infomax_code}, í¬ê¸°: {image.size}")
            
            # í‘œì¤€ ì‚¬ì´ì¦ˆë¡œ ë³€í™˜ (í™˜ê²½ë³€ìˆ˜ IMAGE_SIZES ì‚¬ìš©, ê¸°ë³¸ 240,300)
            sizes_env = os.getenv('IMAGE_SIZES', '240,300')
            try:
                sizes = [int(s.strip()) for s in sizes_env.split(',') if s.strip()]
            except Exception:
                sizes = [240, 300]
            
            formats = ['PNG', 'WebP']
            
            # ì›ë³¸ë„ ì €ì¥ (SVGì¸ ê²½ìš°)
            if image_data.startswith(b'<svg') or image_data.startswith(b'<?xml'):
                results["original"] = image_data
            
            for size in sizes:
                for format_type in formats:
                    try:
                        # ë¦¬ì‚¬ì´ì¦ˆ
                        resized = image.resize((size, size), Image.Resampling.LANCZOS)
                        
                        # ë°”ì´íŠ¸ë¡œ ë³€í™˜
                        output = BytesIO()
                        if format_type == 'PNG':
                            resized.save(output, format='PNG', optimize=True)
                        else:  # WebP
                            resized.save(output, format='WebP', quality=85, optimize=True)
                        
                        converted_data = output.getvalue()
                        results[f"{format_type.lower()}_{size}"] = converted_data
                        print(f"âœ… ì´ë¯¸ì§€ ë³€í™˜ ì™„ë£Œ: {format_type.lower()}_{size}px ({len(converted_data)} bytes)")
                        
                    except Exception as e:
                        print(f"âŒ ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨ ({format_type}_{size}px): {e}")
                        continue
            
            logger.info(f"ì´ë¯¸ì§€ ë³€í™˜ ì™„ë£Œ: {infomax_code}, {len(results)}ê°œ íŒŒì¼")
            return results
            
        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ ë³€í™˜ ì˜¤ë¥˜ ({infomax_code}): {e}")
            # ë³€í™˜ ì‹¤íŒ¨í•´ë„ ì›ë³¸ì€ ì €ì¥
            result = {"original": image_data}
            logger.info(f"ë³€í™˜ ì‹¤íŒ¨ë¡œ ì›ë³¸ë§Œ ë°˜í™˜: {len(result)}ê°œ")
            return result
    
    async def save_to_minio(self, image_data: bytes, object_key: str, content_type: str = "image/png"):
        """MinIOì— ì´ë¯¸ì§€ ì €ì¥"""
        try:
            self.minio_client.put_object(
                self.bucket,
                object_key,
                BytesIO(image_data),
                len(image_data),
                content_type=content_type
            )
            return True
        except Exception as e:
            print(f"MinIO ì €ì¥ ì˜¤ë¥˜: {e}")
            return False
    
    async def save_to_database(self, infomax_code: str, logo_hash: str, file_info: Dict):
        """ë°ì´í„°ë² ì´ìŠ¤ì— ë¡œê³  ì •ë³´ ì €ì¥ (ì§ì ‘ API í˜¸ì¶œ)"""
        print(f"ğŸ” DB ì €ì¥ ì‹œì‘: {infomax_code}, {logo_hash}")
        print(f"ğŸ” file_info: {file_info}")
        try:
            # ì§ì ‘ ê¸°ì¡´ API í˜¸ì¶œ
            timeout = aiohttp.ClientTimeout(total=15)
            async with aiohttp.ClientSession(timeout=timeout) as session:
                
                # 1. logos í…Œì´ë¸” í™•ì¸/ìƒì„±
                logo_url = f"{self.existing_api_base}/api/schemas/raw_data/tables/logos/query"
                logo_params = {
                    "search_column": "logo_hash",
                    "search": logo_hash,
                    "limit": 1
                }
                
                async with session.get(logo_url, params=logo_params) as response:
                    if response.status == 200:
                        logo_data = await response.json()
                        if logo_data and 'data' in logo_data and logo_data['data']:
                            logo_id = logo_data['data'][0]['logo_id']
                            print(f"âœ… ê¸°ì¡´ logos ë°ì´í„° ì‚¬ìš©: logo_id={logo_id}")
                        else:
                            # ìƒˆë¡œ ìƒì„±
                            logo_upsert_url = f"{self.existing_api_base}/api/schemas/raw_data/tables/logos/upsert"
                            logo_upsert_data = {
                                "data": {
                                    "logo_hash": logo_hash,
                                    "is_deleted": False
                                },
                                "conflict_columns": ["logo_hash"]
                            }
                            
                            async with session.post(logo_upsert_url, json=logo_upsert_data) as upsert_response:
                                if upsert_response.status == 200:
                                    upsert_data = await upsert_response.json()
                                    logo_id = upsert_data['data']['logo_id']
                                    print(f"âœ… logos í…Œì´ë¸” ì €ì¥ ì„±ê³µ: logo_id={logo_id}")
                                else:
                                    print(f"âŒ logos í…Œì´ë¸” ì €ì¥ ì‹¤íŒ¨: {upsert_response.status}")
                                    return False
                    else:
                        print(f"âŒ logos í…Œì´ë¸” ì¡°íšŒ ì‹¤íŒ¨: {response.status}")
                        return False
                
                # 2. logo_files í…Œì´ë¸” ì €ì¥
                file_url = f"{self.existing_api_base}/api/schemas/raw_data/tables/logo_files/upsert"
                file_data = {
                    "data": {
                        "logo_id": logo_id,
                        "file_format": file_info['format'],
                        "dimension_width": file_info['dimension_width'],
                        "dimension_height": file_info['dimension_height'],
                        "file_size": file_info['file_size'],
                        "minio_object_key": file_info['object_key'],
                        "data_source": file_info['data_source'],
                        "upload_type": "crawled",
                        "is_original": file_info.get('is_original', True)
                    },
                    "conflict_columns": ["minio_object_key"]
                }
                
                print(f"ğŸ” logo_files ì €ì¥ ë°ì´í„°: {file_data}")
                
                async with session.post(file_url, json=file_data) as file_response:
                    if file_response.status == 200:
                        print(f"âœ… logo_files í…Œì´ë¸” ì €ì¥ ì„±ê³µ: logo_id={logo_id}")
                        print(f"âœ… DB ì €ì¥ ì™„ë£Œ: {infomax_code}")
                        return True
                    else:
                        error_text = await file_response.text()
                        print(f"âŒ logo_files í…Œì´ë¸” ì €ì¥ ì‹¤íŒ¨: {file_response.status}")
                        print(f"âŒ ì˜¤ë¥˜ ë‚´ìš©: {error_text}")
                        return False
                        
        except Exception as e:
            print(f"ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì˜¤ë¥˜: {e}")
            return False
    
    async def crawl_logo(self, infomax_code: str, ticker: str, api_domain: str = None) -> bool:
        """ë¡œê³  í¬ë¡¤ë§ ë©”ì¸ í•¨ìˆ˜"""
        print(f"ğŸ”ğŸ”ğŸ” CRAWL_LOGO í•¨ìˆ˜ ì§„ì…: {infomax_code}")
        print(f"ğŸ”ğŸ”ğŸ” íŒŒë¼ë¯¸í„°: ticker={ticker}, api_domain={api_domain}")
        try:
            print(f"ğŸ” í¬ë¡¤ë§ ì‹œì‘: {infomax_code}, ticker={ticker}, api_domain={api_domain}")
            print(f"ğŸ” í•¨ìˆ˜ ì§„ì… í™•ì¸: {infomax_code}")
            
            # íƒ€ì„ì•„ì›ƒ ì„¤ì • (30ì´ˆ)
            import asyncio
            try:
                print(f"ğŸ” _crawl_logo_internal í˜¸ì¶œ ì „: {infomax_code}")
                print(f"ğŸ” asyncio.wait_for ì‹œì‘: {infomax_code}")
                result = await asyncio.wait_for(
                    self._crawl_logo_internal(infomax_code, ticker, api_domain),
                    timeout=30.0
                )
                print(f"ğŸ” _crawl_logo_internal í˜¸ì¶œ í›„: {infomax_code}, ê²°ê³¼: {result}")
                print(f"ğŸ”ğŸ”ğŸ” CRAWL_LOGO í•¨ìˆ˜ ì™„ë£Œ: {infomax_code}, ê²°ê³¼: {result}")
                return result
            except asyncio.TimeoutError:
                print(f"ğŸ” í¬ë¡¤ë§ íƒ€ì„ì•„ì›ƒ: {infomax_code}")
                return False
            except Exception as e:
                print(f"ğŸ” asyncio.wait_for ì˜¤ë¥˜: {infomax_code} - {e}")
                import traceback
                print(f"ğŸ” asyncio ì˜¤ë¥˜ ìƒì„¸: {traceback.format_exc()}")
                return False
                
        except Exception as e:
            print(f"ğŸ” í¬ë¡¤ë§ í•¨ìˆ˜ ì˜¤ë¥˜: {infomax_code} - {e}")
            import traceback
            print(f"ğŸ” ì˜¤ë¥˜ ìƒì„¸: {traceback.format_exc()}")
            return False
    
    async def _crawl_logo_internal(self, infomax_code: str, ticker: str, api_domain: str = None) -> bool:
        """ë¡œê³  í¬ë¡¤ë§ ë‚´ë¶€ í•¨ìˆ˜"""
        try:
            print(f"ğŸ” ë‚´ë¶€ í•¨ìˆ˜ ì§„ì…: {infomax_code}")
            image_data = None
            data_source = None
            logo_hash = None
            
            # ì›¹ì‚¬ì´íŠ¸ì—ì„œ í¬ë¡¤ë§ ì‹œë„ (tickerê°€ ìˆì„ ë•Œë§Œ)
            if ticker and ticker.strip():
                print(f"ğŸ” ì›¹ì‚¬ì´íŠ¸ í¬ë¡¤ë§ ì‹œë„: {infomax_code}")
                try:
                    image_data = await self.crawl_website(infomax_code, ticker)
                    print(f"ğŸ” crawl_website ë°˜í™˜ê°’ í™•ì¸: {infomax_code}, íƒ€ì…: {type(image_data)}, ê¸¸ì´: {len(image_data) if image_data else 'None'}")
                    if image_data:
                        data_source = "website"
                        logo_hash = hashlib.md5(f"website_{infomax_code}".encode()).hexdigest()
                        print(f"ğŸ” ì›¹ì‚¬ì´íŠ¸ í¬ë¡¤ë§ ì„±ê³µ: {infomax_code}")
                    else:
                        print(f"ğŸ” ì›¹ì‚¬ì´íŠ¸ í¬ë¡¤ë§ ì‹¤íŒ¨: {infomax_code}")
                except Exception as e:
                    print(f"ğŸ” ì›¹ì‚¬ì´íŠ¸ í¬ë¡¤ë§ ì˜¤ë¥˜: {infomax_code} - {e}")
            
            # ì›¹ì‚¬ì´íŠ¸ ì‹¤íŒ¨ ì‹œ logo.dev ì‹œë„
            if not image_data and api_domain:
                print(f"ğŸ” logo.dev í¬ë¡¤ë§ ì‹œë„: {infomax_code}")
                try:
                    image_data = await self.crawl_logo_dev(infomax_code, api_domain)
                    if image_data:
                        data_source = "logo_dev"
                        logo_hash = hashlib.md5(f"logo_dev_{infomax_code}".encode()).hexdigest()
                        print(f"ğŸ” logo.dev í¬ë¡¤ë§ ì„±ê³µ: {infomax_code}")
                    else:
                        print(f"ğŸ” logo.dev í¬ë¡¤ë§ ì‹¤íŒ¨: {infomax_code}")
                except Exception as e:
                    print(f"ğŸ” logo.dev í¬ë¡¤ë§ ì˜¤ë¥˜: {infomax_code} - {e}")
            
            if not image_data:
                print(f"âŒ ëª¨ë“  í¬ë¡¤ë§ ì‹œë„ ì‹¤íŒ¨: {infomax_code}")
                return False
            
            # ì´ë¯¸ì§€ ë³€í™˜
            print(f"ğŸ” ì´ë¯¸ì§€ ë³€í™˜ ì‹œì‘: {infomax_code}")
            try:
                converted_images = self.convert_image(image_data, infomax_code)
                print(f"ğŸ” ì´ë¯¸ì§€ ë³€í™˜ ì™„ë£Œ: {infomax_code}")
            except Exception as e:
                print(f"âŒ ì´ë¯¸ì§€ ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {infomax_code} - {e}")
                converted_images = {"original": image_data}
            
            # masterì—ì„œ logo_hash ì¡°íšŒ
            print(f"ğŸ” masterì—ì„œ logo_hash ì¡°íšŒ: {infomax_code}")
            try:
                master_result = self.existing_api.query_table("raw_data", "logo_master", {
                    "search_column": "infomax_code",
                    "search": infomax_code,
                    "limit": 1
                })
                print(f"ğŸ” master ì¡°íšŒ ê²°ê³¼: {master_result}")
                
                if master_result and 'data' in master_result and master_result['data']:
                    logo_hash = master_result['data'][0]['logo_hash']
                    print(f"ğŸ” master logo_hash ì¡°íšŒ ì„±ê³µ: {logo_hash}")
                else:
                    print(f"âŒ master logo_hash ì¡°íšŒ ì‹¤íŒ¨: {infomax_code}")
                    return False
            except Exception as e:
                print(f"âŒ master ì¡°íšŒ ì˜¤ë¥˜: {e}")
                return False
            
            # MinIOì— ì €ì¥
            saved_files = []
            print(f"ğŸ” ë³€í™˜ëœ ì´ë¯¸ì§€ ê°œìˆ˜: {len(converted_images)}")
            for format_key, img_data in converted_images.items():
                if format_key == "original":
                    # masterì˜ logo_hash ì‚¬ìš©
                    object_key = f"{logo_hash}_original.svg"
                    content_type = "image/svg+xml"
                    is_original = True
                    format_type = "svg"
                    size = None
                else:
                    format_type, size = format_key.split('_')
                    # masterì˜ logo_hash ì‚¬ìš©
                    object_key = f"{logo_hash}_{size}.{format_type.lower()}"
                    content_type = f"image/{format_type.lower()}"
                    is_original = False
                
                print(f"ğŸ” MinIO ì €ì¥ ì‹œë„: {object_key}, í¬ê¸°: {len(img_data)} bytes")
                if await self.save_to_minio(img_data, object_key, content_type):
                    print(f"âœ… MinIO ì €ì¥ ì„±ê³µ: {object_key}")
                    file_info = {
                        'object_key': object_key,
                        'format': format_type.lower(),
                        'dimension_width': int(size) if size else None,
                        'dimension_height': int(size) if size else None,
                        'file_size': len(img_data),
                        'is_original': is_original,
                        'data_source': data_source
                    }
                    saved_files.append(file_info)
                    print(f"ğŸ” íŒŒì¼ ì •ë³´ ì¶”ê°€: {file_info}")
                else:
                    print(f"âŒ MinIO ì €ì¥ ì‹¤íŒ¨: {object_key}")
            
            # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
            print(f"ğŸ” saved_files ê°œìˆ˜: {len(saved_files)}")
            if not saved_files:
                print(f"âŒ ì €ì¥í•  íŒŒì¼ì´ ì—†ìŒ: {infomax_code}")
                return False
                
            for file_info in saved_files:
                print(f"ğŸ” íŒŒì¼ ì €ì¥: {file_info}")
                # DB ì €ì¥ì€ API ì„œë²„ì—ì„œ ì²˜ë¦¬í•˜ë„ë¡ í•¨
                print(f"âœ… íŒŒì¼ ì €ì¥ ì™„ë£Œ (DBëŠ” ë³„ë„ ì²˜ë¦¬): {infomax_code}")
                # DB ì €ì¥ ë¹„í™œì„±í™” - API ì„œë²„ì—ì„œ ì²˜ë¦¬
                # save_to_database í•¨ìˆ˜ í˜¸ì¶œ ì™„ì „ ì œê±°
            
            print(f"ë¡œê³  í¬ë¡¤ë§ ì„±ê³µ: {infomax_code} ({len(saved_files)}ê°œ íŒŒì¼)")
            return True
            
        except Exception as e:
            print(f"ë¡œê³  í¬ë¡¤ë§ ì˜¤ë¥˜ ({infomax_code}): {e}")
            return False
    
    async def crawl_batch(self, tickers: List[Dict], job_id: str = None) -> str:
        """ë°°ì¹˜ í¬ë¡¤ë§ ì‹¤í–‰"""
        if not job_id:
            job_id = f"crawl_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # ì§„í–‰ìƒí™© íŒŒì¼ ìƒì„±
        progress_file = Path("progress") / f"{job_id}.json"
        progress_file.parent.mkdir(exist_ok=True)
        
        progress_data = {
            "job_id": job_id,
            "status": "running",
            "total": len(tickers),
            "completed": 0,
            "success": 0,
            "failed": 0,
            "current": "",
            "started_at": datetime.now().isoformat(),
            "errors": []
        }
        
        with open(progress_file, 'w', encoding='utf-8') as f:
            json.dump(progress_data, f, ensure_ascii=False, indent=2)
        
        try:
            for i, ticker_info in enumerate(tickers):
                infomax_code = ticker_info['infomax_code']
                ticker = ticker_info['ticker']
                api_domain = ticker_info.get('api_domain')
                
                # ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸
                progress_data['current'] = f"{infomax_code} ({ticker})"
                progress_data['completed'] = i
                
                with open(progress_file, 'w', encoding='utf-8') as f:
                    json.dump(progress_data, f, ensure_ascii=False, indent=2)
                
                # í¬ë¡¤ë§ ì‹¤í–‰
                success = await self.crawl_logo(infomax_code, ticker, api_domain)
                
                if success:
                    progress_data['success'] += 1
                else:
                    progress_data['failed'] += 1
                    progress_data['errors'].append(f"Failed: {infomax_code}")
            
            # ì™„ë£Œ ì²˜ë¦¬
            progress_data['status'] = "completed"
            progress_data['completed'] = len(tickers)
            progress_data['finished_at'] = datetime.now().isoformat()
            
            with open(progress_file, 'w', encoding='utf-8') as f:
                json.dump(progress_data, f, ensure_ascii=False, indent=2)
            
            return job_id
            
        except Exception as e:
            progress_data['status'] = "error"
            progress_data['error'] = str(e)
            progress_data['finished_at'] = datetime.now().isoformat()
            
            with open(progress_file, 'w', encoding='utf-8') as f:
                json.dump(progress_data, f, ensure_ascii=False, indent=2)
            
            raise e
